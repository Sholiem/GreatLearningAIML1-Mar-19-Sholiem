{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>8.512640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.836986</td>\n",
       "      <td>70.857109</td>\n",
       "      <td>70.118414</td>\n",
       "      <td>71.543476</td>\n",
       "      <td>5.415113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.695876</td>\n",
       "      <td>83.689686</td>\n",
       "      <td>82.877294</td>\n",
       "      <td>84.465504</td>\n",
       "      <td>1.249468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.840000</td>\n",
       "      <td>33.849998</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>34.189999</td>\n",
       "      <td>1.221500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.770000</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>52.230000</td>\n",
       "      <td>53.310001</td>\n",
       "      <td>2.476250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.879997</td>\n",
       "      <td>79.889999</td>\n",
       "      <td>79.110001</td>\n",
       "      <td>80.610001</td>\n",
       "      <td>5.222500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1584.439941</td>\n",
       "      <td>1578.130005</td>\n",
       "      <td>1549.939941</td>\n",
       "      <td>1600.930054</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open          close            low           high  \\\n",
       "count  851264.000000  851264.000000  851264.000000  851264.000000   \n",
       "mean       70.836986      70.857109      70.118414      71.543476   \n",
       "std        83.695876      83.689686      82.877294      84.465504   \n",
       "min         0.850000       0.860000       0.830000       0.880000   \n",
       "25%        33.840000      33.849998      33.480000      34.189999   \n",
       "50%        52.770000      52.799999      52.230000      53.310001   \n",
       "75%        79.879997      79.889999      79.110001      80.610001   \n",
       "max      1584.439941    1578.130005    1549.939941    1600.930054   \n",
       "\n",
       "             volume  \n",
       "count  8.512640e+05  \n",
       "mean   5.415113e+06  \n",
       "std    1.249468e+07  \n",
       "min    0.000000e+00  \n",
       "25%    1.221500e+06  \n",
       "50%    2.476250e+06  \n",
       "75%    5.222500e+06  \n",
       "max    8.596434e+08  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 851264 entries, 0 to 851263\n",
      "Data columns (total 7 columns):\n",
      "date      851264 non-null object\n",
      "symbol    851264 non-null object\n",
      "open      851264 non-null float64\n",
      "close     851264 non-null float64\n",
      "low       851264 non-null float64\n",
      "high      851264 non-null float64\n",
      "volume    851264 non-null float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data.drop(['date','symbol'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "data1000=data.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data1000.drop('close',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data1000['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                        random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 800  # input layer (28x28 pixels)\n",
    "n_hidden1 = 512  # 1st hidden layer\n",
    "n_hidden2 = 256  # 2nd hidden layer\n",
    "n_hidden3 = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "X1 = tf.placeholder(tf.float32, [None, 4], \"X_in\") \n",
    "y1 = tf.placeholder(tf.float32, [None],\"y_in\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set model weights and bias \n",
    "#W = tf.Variable(np.random.randn(), name=\"weight\") \n",
    "#W = tf.Variable(tf.random_normal([4, 1]), name=\"w\")\n",
    "W = tf.Variable(np.random.rand(4,1), name=\"w\",dtype=tf.float64)\n",
    "b = tf.Variable(np.random.randn(), name=\"b\",dtype=tf.float64)   \n",
    "#W=tf.Variable(tf.truncated_normal([4, 1], stddev=0.1))\n",
    "#b = tf.Variable(np.random.randn(), name=\"bias\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'w_4:0' shape=(4, 1) dtype=float64_ref>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4, 1]), name=\"w\")\n",
    "b = tf.Variable(np.random.randn(), name=\"b\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'b_5:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.add(tf.matmul(X1,W),b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cost = tf.reduce_sum(tf.square(linear_model - y1)) / (2*n_samples)\n",
    "cost = tf.reduce_mean(tf.square(tf.subtract(y1, linear_model))) /n_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters \n",
    "learning_rate = 0.01\n",
    "training_epochs = 2000\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(tf.subtract(y1, linear_model))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "#done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "#sess.run(W)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(linear_model, feed_dict={X1: x_train, y1: y_train}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 3568.5435 [[ 0.9710834]\n",
      " [-1.9813625]\n",
      " [ 1.0141311]\n",
      " [ 0.0548731]] 65.43455\n",
      "400 3567.2134 [[ 0.96976095]\n",
      " [-1.9817475 ]\n",
      " [ 1.0122203 ]\n",
      " [ 0.00392726]] 66.56713\n",
      "600 3567.2131 [[ 9.6934223e-01]\n",
      " [-1.9811661e+00]\n",
      " [ 1.0116440e+00]\n",
      " [ 1.2760005e-03]] 66.58711\n",
      "800 3567.2134 [[ 9.6905333e-01]\n",
      " [-1.9804522e+00]\n",
      " [ 1.0112038e+00]\n",
      " [ 1.1856825e-03]] 66.58732\n",
      "1000 3567.2134 [[ 9.6876723e-01]\n",
      " [-1.9797369e+00]\n",
      " [ 1.0107741e+00]\n",
      " [ 1.1829180e-03]] 66.58732\n",
      "1200 3567.2131 [[ 9.6848112e-01]\n",
      " [-1.9790217e+00]\n",
      " [ 1.0103450e+00]\n",
      " [ 1.1824634e-03]] 66.58732\n",
      "1400 3567.2134 [[ 9.6819502e-01]\n",
      " [-1.9783064e+00]\n",
      " [ 1.0099158e+00]\n",
      " [ 1.1820325e-03]] 66.58732\n",
      "1600 3567.2134 [[ 9.6790892e-01]\n",
      " [-1.9775912e+00]\n",
      " [ 1.0094867e+00]\n",
      " [ 1.1815542e-03]] 66.58732\n",
      "1800 3567.2126 [[ 9.6762282e-01]\n",
      " [-1.9768759e+00]\n",
      " [ 1.0090575e+00]\n",
      " [ 1.1811424e-03]] 66.58732\n",
      "2000 3567.2131 [[ 9.6733671e-01]\n",
      " [-1.9761606e+00]\n",
      " [ 1.0086284e+00]\n",
      " [ 1.1807369e-03]] 66.58732\n",
      "Optimization Finished!\n",
      "Final training cost: 3567.2131 W: [[ 9.6733671e-01]\n",
      " [-1.9761606e+00]\n",
      " [ 1.0086284e+00]\n",
      " [ 1.1807369e-03]] b: 66.58732 \n",
      "\n",
      "[[ 9.6733671e-01]\n",
      " [-1.9761606e+00]\n",
      " [ 1.0086284e+00]\n",
      " [ 1.1807369e-03]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (700,4) not aligned: 1 (dim 1) != 700 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-0e884e168be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Original data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Fitted line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,1) and (700,4) not aligned: 1 (dim 1) != 700 (dim 0)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch the graph \n",
    "with tf.Session() as sess: \n",
    "\t# Load initialized variables in current session \n",
    "\tsess.run(init) \n",
    "\n",
    "\t# Fit all training data \n",
    "\tfor epoch in range(training_epochs): \n",
    "\n",
    "\t\t# perform gradient descent step\n",
    "\t\t#sess.run(linear_model, feed_dict={X1: x_train, y1: y_train})         \n",
    "\t\t#op=sess.run([optimizer,cost], feed_dict={X1: x_train, y1: y_train}) \n",
    "\t\t#print(y_train)\n",
    "\t\tsess.run(optimizer, feed_dict={X1: x_train, y1: y_train}) \n",
    "\t\t#print(sess.run(W))\n",
    "\t\t# Display logs per epoch step \n",
    "\t\tif (epoch+1) % display_step == 0: \n",
    "\t\t\tc = sess.run(cost, feed_dict={X1: x_train, y1: y_train}) \n",
    "\t\t\t#print(\"Epoch:{0:6} \\t Cost:{1:10.4} \\t W:{2:6.4} \\t b:{3:6.4}\". \n",
    "\t\t\t\t#format(epoch+1, c, sess.run(W), sess.run(b)))\n",
    "\t\t\tprint(epoch+1,c,sess.run(W),sess.run(b))\n",
    "\t\t\t\n",
    "\t# Print final parameter values \n",
    "\tprint(\"Optimization Finished!\") \n",
    "# \ttraining_cost = sess.run(cost, feed_dict={X1: x_train, y1: y_train}) \n",
    "\tprint(\"Final training cost:\", c, \"W:\", sess.run(W), \"b:\", \n",
    "\t\tsess.run(b), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [],
   "source": [
    "#done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [],
   "source": [
    "#done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjOInjUROB75"
   },
   "outputs": [],
   "source": [
    "#done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbUPQ2iGTyOC"
   },
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxJfb_2vTyOD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRouHBtITyOF"
   },
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEN7BRzvTyOF"
   },
   "outputs": [],
   "source": [
    "irisDF=pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "5      6            5.4           3.9            1.7           0.4   \n",
       "6      7            4.6           3.4            1.4           0.3   \n",
       "7      8            5.0           3.4            1.5           0.2   \n",
       "8      9            4.4           2.9            1.4           0.2   \n",
       "9     10            4.9           3.1            1.5           0.1   \n",
       "10    11            5.4           3.7            1.5           0.2   \n",
       "11    12            4.8           3.4            1.6           0.2   \n",
       "12    13            4.8           3.0            1.4           0.1   \n",
       "13    14            4.3           3.0            1.1           0.1   \n",
       "14    15            5.8           4.0            1.2           0.2   \n",
       "15    16            5.7           4.4            1.5           0.4   \n",
       "16    17            5.4           3.9            1.3           0.4   \n",
       "17    18            5.1           3.5            1.4           0.3   \n",
       "18    19            5.7           3.8            1.7           0.3   \n",
       "19    20            5.1           3.8            1.5           0.3   \n",
       "20    21            5.4           3.4            1.7           0.2   \n",
       "21    22            5.1           3.7            1.5           0.4   \n",
       "22    23            4.6           3.6            1.0           0.2   \n",
       "23    24            5.1           3.3            1.7           0.5   \n",
       "24    25            4.8           3.4            1.9           0.2   \n",
       "25    26            5.0           3.0            1.6           0.2   \n",
       "26    27            5.0           3.4            1.6           0.4   \n",
       "27    28            5.2           3.5            1.5           0.2   \n",
       "28    29            5.2           3.4            1.4           0.2   \n",
       "29    30            4.7           3.2            1.6           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "120  121            6.9           3.2            5.7           2.3   \n",
       "121  122            5.6           2.8            4.9           2.0   \n",
       "122  123            7.7           2.8            6.7           2.0   \n",
       "123  124            6.3           2.7            4.9           1.8   \n",
       "124  125            6.7           3.3            5.7           2.1   \n",
       "125  126            7.2           3.2            6.0           1.8   \n",
       "126  127            6.2           2.8            4.8           1.8   \n",
       "127  128            6.1           3.0            4.9           1.8   \n",
       "128  129            6.4           2.8            5.6           2.1   \n",
       "129  130            7.2           3.0            5.8           1.6   \n",
       "130  131            7.4           2.8            6.1           1.9   \n",
       "131  132            7.9           3.8            6.4           2.0   \n",
       "132  133            6.4           2.8            5.6           2.2   \n",
       "133  134            6.3           2.8            5.1           1.5   \n",
       "134  135            6.1           2.6            5.6           1.4   \n",
       "135  136            7.7           3.0            6.1           2.3   \n",
       "136  137            6.3           3.4            5.6           2.4   \n",
       "137  138            6.4           3.1            5.5           1.8   \n",
       "138  139            6.0           3.0            4.8           1.8   \n",
       "139  140            6.9           3.1            5.4           2.1   \n",
       "140  141            6.7           3.1            5.6           2.4   \n",
       "141  142            6.9           3.1            5.1           2.3   \n",
       "142  143            5.8           2.7            5.1           1.9   \n",
       "143  144            6.8           3.2            5.9           2.3   \n",
       "144  145            6.7           3.3            5.7           2.5   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "5       Iris-setosa  \n",
       "6       Iris-setosa  \n",
       "7       Iris-setosa  \n",
       "8       Iris-setosa  \n",
       "9       Iris-setosa  \n",
       "10      Iris-setosa  \n",
       "11      Iris-setosa  \n",
       "12      Iris-setosa  \n",
       "13      Iris-setosa  \n",
       "14      Iris-setosa  \n",
       "15      Iris-setosa  \n",
       "16      Iris-setosa  \n",
       "17      Iris-setosa  \n",
       "18      Iris-setosa  \n",
       "19      Iris-setosa  \n",
       "20      Iris-setosa  \n",
       "21      Iris-setosa  \n",
       "22      Iris-setosa  \n",
       "23      Iris-setosa  \n",
       "24      Iris-setosa  \n",
       "25      Iris-setosa  \n",
       "26      Iris-setosa  \n",
       "27      Iris-setosa  \n",
       "28      Iris-setosa  \n",
       "29      Iris-setosa  \n",
       "..              ...  \n",
       "120  Iris-virginica  \n",
       "121  Iris-virginica  \n",
       "122  Iris-virginica  \n",
       "123  Iris-virginica  \n",
       "124  Iris-virginica  \n",
       "125  Iris-virginica  \n",
       "126  Iris-virginica  \n",
       "127  Iris-virginica  \n",
       "128  Iris-virginica  \n",
       "129  Iris-virginica  \n",
       "130  Iris-virginica  \n",
       "131  Iris-virginica  \n",
       "132  Iris-virginica  \n",
       "133  Iris-virginica  \n",
       "134  Iris-virginica  \n",
       "135  Iris-virginica  \n",
       "136  Iris-virginica  \n",
       "137  Iris-virginica  \n",
       "138  Iris-virginica  \n",
       "139  Iris-virginica  \n",
       "140  Iris-virginica  \n",
       "141  Iris-virginica  \n",
       "142  Iris-virginica  \n",
       "143  Iris-virginica  \n",
       "144  Iris-virginica  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wbhz0SgTyOI"
   },
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "If4kadhPTyOJ"
   },
   "outputs": [],
   "source": [
    "xir=irisDF.drop(['Id','Species'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "yir=irisDF['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuLlR5E8TyOP"
   },
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lui4BZRgTyOR"
   },
   "outputs": [],
   "source": [
    "yir=pd.get_dummies(yir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0            1                0               0\n",
       "1            1                0               0\n",
       "2            1                0               0\n",
       "3            1                0               0\n",
       "4            1                0               0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xir=xir.apply(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBCfIFH8TyOV"
   },
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocEfx5TvTyOW"
   },
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(xir, yir, test_size=0.3, \n",
    "                                                        random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N31GZ7-YTyOY"
   },
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.optimizers import SGD \n",
    "from keras.optimizers import Adam\n",
    "from keras import utils \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "0            5.1           3.5            1.4           0.2\n",
       "1            4.9           3.0            1.4           0.2\n",
       "2            4.7           3.2            1.3           0.2\n",
       "3            4.6           3.1            1.5           0.2\n",
       "4            5.0           3.6            1.4           0.2"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "n_inputs = 784 \n",
    "n_classes = 10 \n",
    "n_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mNXvtQiTyOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 1.0985 - acc: 0.3333\n",
      "Epoch 2/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 1.0985 - acc: 0.3524\n",
      "Epoch 3/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0984 - acc: 0.3524\n",
      "Epoch 4/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 1.0983 - acc: 0.3714\n",
      "Epoch 5/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 1.0981 - acc: 0.3714\n",
      "Epoch 6/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 1.0980 - acc: 0.3714\n",
      "Epoch 7/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0978 - acc: 0.4190\n",
      "Epoch 8/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0976 - acc: 0.4476\n",
      "Epoch 9/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 1.0971 - acc: 0.5429\n",
      "Epoch 10/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 1.0966 - acc: 0.5714\n",
      "Epoch 11/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0959 - acc: 0.6000\n",
      "Epoch 12/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 1.0952 - acc: 0.6190\n",
      "Epoch 13/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 1.0944 - acc: 0.6190\n",
      "Epoch 14/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 1.0935 - acc: 0.6190\n",
      "Epoch 15/2000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 1.0922 - acc: 0.6095\n",
      "Epoch 16/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 1.0907 - acc: 0.5905\n",
      "Epoch 17/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 1.0887 - acc: 0.6000\n",
      "Epoch 18/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0864 - acc: 0.6190\n",
      "Epoch 19/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 1.0838 - acc: 0.6286\n",
      "Epoch 20/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 1.0812 - acc: 0.6571\n",
      "Epoch 21/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 1.0784 - acc: 0.6286\n",
      "Epoch 22/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 1.0759 - acc: 0.6000\n",
      "Epoch 23/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 1.0737 - acc: 0.5333\n",
      "Epoch 24/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 1.0721 - acc: 0.4857\n",
      "Epoch 25/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 1.0709 - acc: 0.4286\n",
      "Epoch 26/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 1.0701 - acc: 0.4095\n",
      "Epoch 27/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 1.0692 - acc: 0.3810\n",
      "Epoch 28/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0683 - acc: 0.3810\n",
      "Epoch 29/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 1.0672 - acc: 0.3810\n",
      "Epoch 30/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0660 - acc: 0.3810\n",
      "Epoch 31/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 1.0646 - acc: 0.3810\n",
      "Epoch 32/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0631 - acc: 0.3810\n",
      "Epoch 33/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 1.0616 - acc: 0.3810\n",
      "Epoch 34/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0599 - acc: 0.3810\n",
      "Epoch 35/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 1.0583 - acc: 0.4095\n",
      "Epoch 36/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 1.0568 - acc: 0.4190\n",
      "Epoch 37/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 1.0552 - acc: 0.4476\n",
      "Epoch 38/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 1.0536 - acc: 0.4857\n",
      "Epoch 39/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.0522 - acc: 0.5048\n",
      "Epoch 40/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0508 - acc: 0.5333\n",
      "Epoch 41/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 1.0494 - acc: 0.5619\n",
      "Epoch 42/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 1.0482 - acc: 0.5810\n",
      "Epoch 43/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 1.0472 - acc: 0.6095\n",
      "Epoch 44/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0462 - acc: 0.6095\n",
      "Epoch 45/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 1.0452 - acc: 0.6190\n",
      "Epoch 46/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 1.0442 - acc: 0.6190\n",
      "Epoch 47/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0431 - acc: 0.6190\n",
      "Epoch 48/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.0421 - acc: 0.6190\n",
      "Epoch 49/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 1.0410 - acc: 0.6190\n",
      "Epoch 50/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 1.0399 - acc: 0.6095\n",
      "Epoch 51/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 1.0387 - acc: 0.6095\n",
      "Epoch 52/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 1.0376 - acc: 0.6095\n",
      "Epoch 53/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 1.0365 - acc: 0.5905\n",
      "Epoch 54/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0354 - acc: 0.5810\n",
      "Epoch 55/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 1.0343 - acc: 0.5810\n",
      "Epoch 56/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0331 - acc: 0.5810\n",
      "Epoch 57/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0319 - acc: 0.5810\n",
      "Epoch 58/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0306 - acc: 0.5810\n",
      "Epoch 59/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0293 - acc: 0.5905\n",
      "Epoch 60/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0280 - acc: 0.6000\n",
      "Epoch 61/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 1.0267 - acc: 0.6190\n",
      "Epoch 62/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 1.0254 - acc: 0.6381\n",
      "Epoch 63/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 1.0241 - acc: 0.6381\n",
      "Epoch 64/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 1.0228 - acc: 0.6381\n",
      "Epoch 65/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 1.0216 - acc: 0.6381\n",
      "Epoch 66/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0202 - acc: 0.6381\n",
      "Epoch 67/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 1.0189 - acc: 0.6381\n",
      "Epoch 68/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 1.0176 - acc: 0.6381\n",
      "Epoch 69/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 1.0163 - acc: 0.6381\n",
      "Epoch 70/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 1.0149 - acc: 0.6381\n",
      "Epoch 71/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 1.0136 - acc: 0.6381\n",
      "Epoch 72/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 1.0122 - acc: 0.6476\n",
      "Epoch 73/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 1.0108 - acc: 0.6476\n",
      "Epoch 74/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 1.0094 - acc: 0.6476\n",
      "Epoch 75/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 1.0080 - acc: 0.6476\n",
      "Epoch 76/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 1.0066 - acc: 0.6476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 1.0051 - acc: 0.6571\n",
      "Epoch 78/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 1.0037 - acc: 0.6571\n",
      "Epoch 79/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 1.0022 - acc: 0.6571\n",
      "Epoch 80/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 1.0007 - acc: 0.6571\n",
      "Epoch 81/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9992 - acc: 0.6571\n",
      "Epoch 82/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9977 - acc: 0.6571\n",
      "Epoch 83/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.9962 - acc: 0.6571\n",
      "Epoch 84/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9947 - acc: 0.6571\n",
      "Epoch 85/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.9931 - acc: 0.6571\n",
      "Epoch 86/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.9916 - acc: 0.6571\n",
      "Epoch 87/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.9900 - acc: 0.6571\n",
      "Epoch 88/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.9884 - acc: 0.6571\n",
      "Epoch 89/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.9868 - acc: 0.6571\n",
      "Epoch 90/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.9852 - acc: 0.6571\n",
      "Epoch 91/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.9836 - acc: 0.6571\n",
      "Epoch 92/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.9820 - acc: 0.6571\n",
      "Epoch 93/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.9803 - acc: 0.6571\n",
      "Epoch 94/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.9787 - acc: 0.6571\n",
      "Epoch 95/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.9770 - acc: 0.6571\n",
      "Epoch 96/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.9754 - acc: 0.6571\n",
      "Epoch 97/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.9737 - acc: 0.6571\n",
      "Epoch 98/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.9720 - acc: 0.6571\n",
      "Epoch 99/2000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.9703 - acc: 0.6571\n",
      "Epoch 100/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9685 - acc: 0.6667\n",
      "Epoch 101/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.9668 - acc: 0.6667\n",
      "Epoch 102/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9650 - acc: 0.6667\n",
      "Epoch 103/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.9633 - acc: 0.6667\n",
      "Epoch 104/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9615 - acc: 0.6667\n",
      "Epoch 105/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.9597 - acc: 0.6857\n",
      "Epoch 106/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.9579 - acc: 0.6857\n",
      "Epoch 107/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9562 - acc: 0.6857\n",
      "Epoch 108/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.9544 - acc: 0.6857\n",
      "Epoch 109/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.9525 - acc: 0.6857\n",
      "Epoch 110/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.9507 - acc: 0.6857\n",
      "Epoch 111/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.9489 - acc: 0.6857\n",
      "Epoch 112/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.9470 - acc: 0.6857\n",
      "Epoch 113/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.9452 - acc: 0.6857\n",
      "Epoch 114/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.9433 - acc: 0.6857\n",
      "Epoch 115/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.9414 - acc: 0.6857\n",
      "Epoch 116/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.9396 - acc: 0.6857\n",
      "Epoch 117/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.9377 - acc: 0.6857\n",
      "Epoch 118/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9358 - acc: 0.6857\n",
      "Epoch 119/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.9339 - acc: 0.6857\n",
      "Epoch 120/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.9320 - acc: 0.6857\n",
      "Epoch 121/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.9301 - acc: 0.6952\n",
      "Epoch 122/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.9281 - acc: 0.6952\n",
      "Epoch 123/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.9262 - acc: 0.6952\n",
      "Epoch 124/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.9243 - acc: 0.6952\n",
      "Epoch 125/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9223 - acc: 0.6952\n",
      "Epoch 126/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.9204 - acc: 0.6952\n",
      "Epoch 127/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.9184 - acc: 0.6952\n",
      "Epoch 128/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.9165 - acc: 0.6952\n",
      "Epoch 129/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.9145 - acc: 0.6952\n",
      "Epoch 130/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.9125 - acc: 0.6952\n",
      "Epoch 131/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.9105 - acc: 0.6952\n",
      "Epoch 132/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.9085 - acc: 0.6952\n",
      "Epoch 133/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9066 - acc: 0.6952\n",
      "Epoch 134/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.9046 - acc: 0.6952\n",
      "Epoch 135/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.9026 - acc: 0.6952\n",
      "Epoch 136/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.9006 - acc: 0.6952\n",
      "Epoch 137/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.8986 - acc: 0.6952\n",
      "Epoch 138/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.8966 - acc: 0.6952\n",
      "Epoch 139/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.8946 - acc: 0.6952\n",
      "Epoch 140/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.8925 - acc: 0.6952\n",
      "Epoch 141/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.8905 - acc: 0.6952\n",
      "Epoch 142/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.8885 - acc: 0.6952\n",
      "Epoch 143/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.8865 - acc: 0.6952\n",
      "Epoch 144/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.8845 - acc: 0.6952\n",
      "Epoch 145/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.8824 - acc: 0.6952\n",
      "Epoch 146/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.8804 - acc: 0.6952\n",
      "Epoch 147/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.8784 - acc: 0.6952\n",
      "Epoch 148/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.8764 - acc: 0.6952\n",
      "Epoch 149/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.8743 - acc: 0.6952\n",
      "Epoch 150/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.8723 - acc: 0.6952\n",
      "Epoch 151/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.8703 - acc: 0.6952\n",
      "Epoch 152/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.8682 - acc: 0.6952\n",
      "Epoch 153/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.8662 - acc: 0.6952\n",
      "Epoch 154/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.8642 - acc: 0.6952\n",
      "Epoch 155/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.8622 - acc: 0.6952\n",
      "Epoch 156/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.8601 - acc: 0.6952\n",
      "Epoch 157/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.8581 - acc: 0.6952\n",
      "Epoch 158/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.8561 - acc: 0.6952\n",
      "Epoch 159/2000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.8541 - acc: 0.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.8521 - acc: 0.6952\n",
      "Epoch 161/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.8501 - acc: 0.6952\n",
      "Epoch 162/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.8481 - acc: 0.6952\n",
      "Epoch 163/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.8461 - acc: 0.6952\n",
      "Epoch 164/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.8441 - acc: 0.6952\n",
      "Epoch 165/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.8421 - acc: 0.6952\n",
      "Epoch 166/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.8401 - acc: 0.6952\n",
      "Epoch 167/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.8381 - acc: 0.6952\n",
      "Epoch 168/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.8361 - acc: 0.6952\n",
      "Epoch 169/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.8342 - acc: 0.6952\n",
      "Epoch 170/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.8322 - acc: 0.6952\n",
      "Epoch 171/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.8302 - acc: 0.6952\n",
      "Epoch 172/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.8283 - acc: 0.6952\n",
      "Epoch 173/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.8263 - acc: 0.6952\n",
      "Epoch 174/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.8244 - acc: 0.6952\n",
      "Epoch 175/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.8225 - acc: 0.6952\n",
      "Epoch 176/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.8205 - acc: 0.6952\n",
      "Epoch 177/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.8186 - acc: 0.6952\n",
      "Epoch 178/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.8167 - acc: 0.6952\n",
      "Epoch 179/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.8148 - acc: 0.6952\n",
      "Epoch 180/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.8129 - acc: 0.6952\n",
      "Epoch 181/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.8110 - acc: 0.6952\n",
      "Epoch 182/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.8091 - acc: 0.6952\n",
      "Epoch 183/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.8072 - acc: 0.6952\n",
      "Epoch 184/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.8053 - acc: 0.6952\n",
      "Epoch 185/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.8034 - acc: 0.6952\n",
      "Epoch 186/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.8016 - acc: 0.6952\n",
      "Epoch 187/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.7997 - acc: 0.6952\n",
      "Epoch 188/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.7979 - acc: 0.6952\n",
      "Epoch 189/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.7960 - acc: 0.6952\n",
      "Epoch 190/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7942 - acc: 0.6952\n",
      "Epoch 191/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.7924 - acc: 0.6952\n",
      "Epoch 192/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7906 - acc: 0.6952\n",
      "Epoch 193/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.7888 - acc: 0.6952\n",
      "Epoch 194/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.7870 - acc: 0.6952\n",
      "Epoch 195/2000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.7852 - acc: 0.6952\n",
      "Epoch 196/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7834 - acc: 0.6952\n",
      "Epoch 197/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7817 - acc: 0.6952\n",
      "Epoch 198/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.7799 - acc: 0.6952\n",
      "Epoch 199/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.7782 - acc: 0.6952\n",
      "Epoch 200/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7764 - acc: 0.6952\n",
      "Epoch 201/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.7747 - acc: 0.6952\n",
      "Epoch 202/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.7730 - acc: 0.6952\n",
      "Epoch 203/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.7713 - acc: 0.6952\n",
      "Epoch 204/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.7696 - acc: 0.6952\n",
      "Epoch 205/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.7679 - acc: 0.6952\n",
      "Epoch 206/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7662 - acc: 0.6952\n",
      "Epoch 207/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.7645 - acc: 0.6952\n",
      "Epoch 208/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.7629 - acc: 0.6952\n",
      "Epoch 209/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.7612 - acc: 0.6952\n",
      "Epoch 210/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.7595 - acc: 0.6952\n",
      "Epoch 211/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7579 - acc: 0.6952\n",
      "Epoch 212/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.7562 - acc: 0.6952\n",
      "Epoch 213/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.7546 - acc: 0.6952\n",
      "Epoch 214/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7530 - acc: 0.6952\n",
      "Epoch 215/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.7513 - acc: 0.6952\n",
      "Epoch 216/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7497 - acc: 0.6952\n",
      "Epoch 217/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.7481 - acc: 0.6952\n",
      "Epoch 218/2000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.7465 - acc: 0.6952\n",
      "Epoch 219/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.7449 - acc: 0.6952\n",
      "Epoch 220/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.7433 - acc: 0.6952\n",
      "Epoch 221/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.7417 - acc: 0.6952\n",
      "Epoch 222/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.7401 - acc: 0.6952\n",
      "Epoch 223/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.7386 - acc: 0.6952\n",
      "Epoch 224/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.7370 - acc: 0.7048\n",
      "Epoch 225/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.7354 - acc: 0.7048\n",
      "Epoch 226/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.7338 - acc: 0.7048\n",
      "Epoch 227/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.7323 - acc: 0.7048\n",
      "Epoch 228/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.7307 - acc: 0.7143\n",
      "Epoch 229/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.7292 - acc: 0.7238\n",
      "Epoch 230/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7277 - acc: 0.7238\n",
      "Epoch 231/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.7261 - acc: 0.7238\n",
      "Epoch 232/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.7246 - acc: 0.7238\n",
      "Epoch 233/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.7231 - acc: 0.7429\n",
      "Epoch 234/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.7216 - acc: 0.7429\n",
      "Epoch 235/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.7201 - acc: 0.7429\n",
      "Epoch 236/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.7186 - acc: 0.7429\n",
      "Epoch 237/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.7171 - acc: 0.7429\n",
      "Epoch 238/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.7156 - acc: 0.7429\n",
      "Epoch 239/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.7142 - acc: 0.7429\n",
      "Epoch 240/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.7127 - acc: 0.7429\n",
      "Epoch 241/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.7112 - acc: 0.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.7098 - acc: 0.7524\n",
      "Epoch 243/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.7083 - acc: 0.7524\n",
      "Epoch 244/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.7069 - acc: 0.7619\n",
      "Epoch 245/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.7055 - acc: 0.7714\n",
      "Epoch 246/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.7041 - acc: 0.7714\n",
      "Epoch 247/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.7027 - acc: 0.7714\n",
      "Epoch 248/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.7013 - acc: 0.7714\n",
      "Epoch 249/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.7000 - acc: 0.7714\n",
      "Epoch 250/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6986 - acc: 0.7714\n",
      "Epoch 251/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6973 - acc: 0.7714\n",
      "Epoch 252/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.6959 - acc: 0.7905\n",
      "Epoch 253/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.6946 - acc: 0.7905\n",
      "Epoch 254/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.6933 - acc: 0.7905\n",
      "Epoch 255/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.6919 - acc: 0.8000\n",
      "Epoch 256/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.6906 - acc: 0.8000\n",
      "Epoch 257/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.6893 - acc: 0.8000\n",
      "Epoch 258/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.6880 - acc: 0.8000\n",
      "Epoch 259/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6868 - acc: 0.8000\n",
      "Epoch 260/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.6855 - acc: 0.8095\n",
      "Epoch 261/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.6842 - acc: 0.8095\n",
      "Epoch 262/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6830 - acc: 0.8190\n",
      "Epoch 263/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6817 - acc: 0.8190\n",
      "Epoch 264/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.6805 - acc: 0.8190\n",
      "Epoch 265/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.6792 - acc: 0.8190\n",
      "Epoch 266/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.6780 - acc: 0.8190\n",
      "Epoch 267/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.6768 - acc: 0.8190\n",
      "Epoch 268/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.6756 - acc: 0.8190\n",
      "Epoch 269/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6744 - acc: 0.8190\n",
      "Epoch 270/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6732 - acc: 0.8190\n",
      "Epoch 271/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6720 - acc: 0.8190\n",
      "Epoch 272/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6708 - acc: 0.8190\n",
      "Epoch 273/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6697 - acc: 0.8190\n",
      "Epoch 274/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.6685 - acc: 0.8190\n",
      "Epoch 275/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.6673 - acc: 0.8190\n",
      "Epoch 276/2000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.6662 - acc: 0.8286\n",
      "Epoch 277/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.6650 - acc: 0.8286\n",
      "Epoch 278/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6639 - acc: 0.8381\n",
      "Epoch 279/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.6627 - acc: 0.8381\n",
      "Epoch 280/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.6616 - acc: 0.8381\n",
      "Epoch 281/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.6605 - acc: 0.8381\n",
      "Epoch 282/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6594 - acc: 0.8381\n",
      "Epoch 283/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6582 - acc: 0.8571\n",
      "Epoch 284/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6571 - acc: 0.8571\n",
      "Epoch 285/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.6560 - acc: 0.8571\n",
      "Epoch 286/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.6549 - acc: 0.8571\n",
      "Epoch 287/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.6539 - acc: 0.8667\n",
      "Epoch 288/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6528 - acc: 0.8667\n",
      "Epoch 289/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.6517 - acc: 0.8667\n",
      "Epoch 290/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6506 - acc: 0.8667\n",
      "Epoch 291/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6496 - acc: 0.8667\n",
      "Epoch 292/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.6485 - acc: 0.8667\n",
      "Epoch 293/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.6475 - acc: 0.8667\n",
      "Epoch 294/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6464 - acc: 0.8667\n",
      "Epoch 295/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6453 - acc: 0.8762\n",
      "Epoch 296/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.6443 - acc: 0.8762\n",
      "Epoch 297/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.6433 - acc: 0.8762\n",
      "Epoch 298/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.6422 - acc: 0.8762\n",
      "Epoch 299/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.6412 - acc: 0.8857\n",
      "Epoch 300/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6402 - acc: 0.8952\n",
      "Epoch 301/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.6391 - acc: 0.8952\n",
      "Epoch 302/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.6381 - acc: 0.8952\n",
      "Epoch 303/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6371 - acc: 0.8952\n",
      "Epoch 304/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6361 - acc: 0.8952\n",
      "Epoch 305/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.6351 - acc: 0.9048\n",
      "Epoch 306/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6340 - acc: 0.9048\n",
      "Epoch 307/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.6330 - acc: 0.9048\n",
      "Epoch 308/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6321 - acc: 0.9048\n",
      "Epoch 309/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.6311 - acc: 0.9048\n",
      "Epoch 310/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6301 - acc: 0.9048\n",
      "Epoch 311/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6291 - acc: 0.9238\n",
      "Epoch 312/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6281 - acc: 0.9238\n",
      "Epoch 313/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6271 - acc: 0.9238\n",
      "Epoch 314/2000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.6261 - acc: 0.9238\n",
      "Epoch 315/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6252 - acc: 0.9238\n",
      "Epoch 316/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6242 - acc: 0.9238\n",
      "Epoch 317/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6233 - acc: 0.9238\n",
      "Epoch 318/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.6223 - acc: 0.9238\n",
      "Epoch 319/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.6214 - acc: 0.9238\n",
      "Epoch 320/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6204 - acc: 0.9238\n",
      "Epoch 321/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.6195 - acc: 0.9238\n",
      "Epoch 322/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.6185 - acc: 0.9238\n",
      "Epoch 323/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.6176 - acc: 0.9238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.6167 - acc: 0.9238\n",
      "Epoch 325/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6158 - acc: 0.9238\n",
      "Epoch 326/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.6149 - acc: 0.9238\n",
      "Epoch 327/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.6139 - acc: 0.9238\n",
      "Epoch 328/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.6130 - acc: 0.9238\n",
      "Epoch 329/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6121 - acc: 0.9238\n",
      "Epoch 330/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.6112 - acc: 0.9238\n",
      "Epoch 331/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.6103 - acc: 0.9333\n",
      "Epoch 332/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6094 - acc: 0.9333\n",
      "Epoch 333/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.6085 - acc: 0.9333\n",
      "Epoch 334/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.6076 - acc: 0.9333\n",
      "Epoch 335/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.6068 - acc: 0.9333\n",
      "Epoch 336/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.6059 - acc: 0.9333\n",
      "Epoch 337/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.6050 - acc: 0.9333\n",
      "Epoch 338/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.6041 - acc: 0.9333\n",
      "Epoch 339/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.6032 - acc: 0.9429\n",
      "Epoch 340/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.6024 - acc: 0.9429\n",
      "Epoch 341/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.6015 - acc: 0.9429\n",
      "Epoch 342/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.6007 - acc: 0.9429\n",
      "Epoch 343/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5998 - acc: 0.9429\n",
      "Epoch 344/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5989 - acc: 0.9429\n",
      "Epoch 345/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5981 - acc: 0.9429\n",
      "Epoch 346/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.5972 - acc: 0.9429\n",
      "Epoch 347/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5964 - acc: 0.9429\n",
      "Epoch 348/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5955 - acc: 0.9429\n",
      "Epoch 349/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.5947 - acc: 0.9429\n",
      "Epoch 350/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.5938 - acc: 0.9429\n",
      "Epoch 351/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5930 - acc: 0.9429\n",
      "Epoch 352/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5922 - acc: 0.9429\n",
      "Epoch 353/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.5913 - acc: 0.9429\n",
      "Epoch 354/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5905 - acc: 0.9429\n",
      "Epoch 355/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5897 - acc: 0.9429\n",
      "Epoch 356/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5888 - acc: 0.9429\n",
      "Epoch 357/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5880 - acc: 0.9429\n",
      "Epoch 358/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5872 - acc: 0.9429\n",
      "Epoch 359/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5864 - acc: 0.9429\n",
      "Epoch 360/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5856 - acc: 0.9429\n",
      "Epoch 361/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5847 - acc: 0.9429\n",
      "Epoch 362/2000\n",
      "105/105 [==============================] - 0s 35us/step - loss: 0.5839 - acc: 0.9429\n",
      "Epoch 363/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.5831 - acc: 0.9429\n",
      "Epoch 364/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5823 - acc: 0.9429\n",
      "Epoch 365/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5815 - acc: 0.9429\n",
      "Epoch 366/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5807 - acc: 0.9429\n",
      "Epoch 367/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.5799 - acc: 0.9429\n",
      "Epoch 368/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5791 - acc: 0.9429\n",
      "Epoch 369/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5783 - acc: 0.9429\n",
      "Epoch 370/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.5775 - acc: 0.9429\n",
      "Epoch 371/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5767 - acc: 0.9429\n",
      "Epoch 372/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5759 - acc: 0.9429\n",
      "Epoch 373/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.5751 - acc: 0.9429\n",
      "Epoch 374/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.5743 - acc: 0.9429\n",
      "Epoch 375/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5735 - acc: 0.9524\n",
      "Epoch 376/2000\n",
      "105/105 [==============================] - 0s 87us/step - loss: 0.5727 - acc: 0.9524\n",
      "Epoch 377/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5719 - acc: 0.9524\n",
      "Epoch 378/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5711 - acc: 0.9524\n",
      "Epoch 379/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.5704 - acc: 0.9524\n",
      "Epoch 380/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5696 - acc: 0.9524\n",
      "Epoch 381/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.5688 - acc: 0.9524\n",
      "Epoch 382/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5680 - acc: 0.9524\n",
      "Epoch 383/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5672 - acc: 0.9524\n",
      "Epoch 384/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.5664 - acc: 0.9524\n",
      "Epoch 385/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5657 - acc: 0.9524\n",
      "Epoch 386/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5649 - acc: 0.9524\n",
      "Epoch 387/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5641 - acc: 0.9524\n",
      "Epoch 388/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.5634 - acc: 0.9524\n",
      "Epoch 389/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.5626 - acc: 0.9524\n",
      "Epoch 390/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5618 - acc: 0.9524\n",
      "Epoch 391/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.5611 - acc: 0.9524\n",
      "Epoch 392/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.5603 - acc: 0.9524\n",
      "Epoch 393/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.5595 - acc: 0.9524\n",
      "Epoch 394/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5588 - acc: 0.9524\n",
      "Epoch 395/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5580 - acc: 0.9524\n",
      "Epoch 396/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5572 - acc: 0.9524\n",
      "Epoch 397/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5565 - acc: 0.9524\n",
      "Epoch 398/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.5557 - acc: 0.9524\n",
      "Epoch 399/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.5550 - acc: 0.9524\n",
      "Epoch 400/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5542 - acc: 0.9619\n",
      "Epoch 401/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5535 - acc: 0.9619\n",
      "Epoch 402/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5527 - acc: 0.9619\n",
      "Epoch 403/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5519 - acc: 0.9619\n",
      "Epoch 404/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5512 - acc: 0.9619\n",
      "Epoch 405/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5504 - acc: 0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.5497 - acc: 0.9619\n",
      "Epoch 407/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5490 - acc: 0.9619\n",
      "Epoch 408/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5482 - acc: 0.9619\n",
      "Epoch 409/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.5475 - acc: 0.9619\n",
      "Epoch 410/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.5467 - acc: 0.9619\n",
      "Epoch 411/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.5460 - acc: 0.9619\n",
      "Epoch 412/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.5452 - acc: 0.9619\n",
      "Epoch 413/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5445 - acc: 0.9619\n",
      "Epoch 414/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.5438 - acc: 0.9619\n",
      "Epoch 415/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.5430 - acc: 0.9619\n",
      "Epoch 416/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5423 - acc: 0.9619\n",
      "Epoch 417/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5415 - acc: 0.9619\n",
      "Epoch 418/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.5408 - acc: 0.9619\n",
      "Epoch 419/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.5401 - acc: 0.9619\n",
      "Epoch 420/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5393 - acc: 0.9619\n",
      "Epoch 421/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5386 - acc: 0.9619\n",
      "Epoch 422/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5379 - acc: 0.9619\n",
      "Epoch 423/2000\n",
      "105/105 [==============================] - 0s 36us/step - loss: 0.5371 - acc: 0.9619\n",
      "Epoch 424/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5364 - acc: 0.9619\n",
      "Epoch 425/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.5357 - acc: 0.9619\n",
      "Epoch 426/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5350 - acc: 0.9619\n",
      "Epoch 427/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5342 - acc: 0.9619\n",
      "Epoch 428/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5335 - acc: 0.9619\n",
      "Epoch 429/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.5328 - acc: 0.9619\n",
      "Epoch 430/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5321 - acc: 0.9619\n",
      "Epoch 431/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5313 - acc: 0.9619\n",
      "Epoch 432/2000\n",
      "105/105 [==============================] - 0s 93us/step - loss: 0.5306 - acc: 0.9619\n",
      "Epoch 433/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5299 - acc: 0.9619\n",
      "Epoch 434/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5292 - acc: 0.9619\n",
      "Epoch 435/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.5284 - acc: 0.9619\n",
      "Epoch 436/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5277 - acc: 0.9619\n",
      "Epoch 437/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5270 - acc: 0.9619\n",
      "Epoch 438/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.5263 - acc: 0.9714\n",
      "Epoch 439/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5256 - acc: 0.9714\n",
      "Epoch 440/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.5248 - acc: 0.9714\n",
      "Epoch 441/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.5241 - acc: 0.9714\n",
      "Epoch 442/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.5234 - acc: 0.9714\n",
      "Epoch 443/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5227 - acc: 0.9714\n",
      "Epoch 444/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.5220 - acc: 0.9714\n",
      "Epoch 445/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5213 - acc: 0.9714\n",
      "Epoch 446/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.5205 - acc: 0.9714\n",
      "Epoch 447/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5198 - acc: 0.9714\n",
      "Epoch 448/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5191 - acc: 0.9714\n",
      "Epoch 449/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5184 - acc: 0.9714\n",
      "Epoch 450/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5177 - acc: 0.9714\n",
      "Epoch 451/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.5170 - acc: 0.9714\n",
      "Epoch 452/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.5163 - acc: 0.9714\n",
      "Epoch 453/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5156 - acc: 0.9714\n",
      "Epoch 454/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5149 - acc: 0.9714\n",
      "Epoch 455/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5141 - acc: 0.9714\n",
      "Epoch 456/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5134 - acc: 0.9714\n",
      "Epoch 457/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.5127 - acc: 0.9714\n",
      "Epoch 458/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5120 - acc: 0.9714\n",
      "Epoch 459/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.5113 - acc: 0.9714\n",
      "Epoch 460/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5106 - acc: 0.9714\n",
      "Epoch 461/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5099 - acc: 0.9714\n",
      "Epoch 462/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5092 - acc: 0.9619\n",
      "Epoch 463/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.5085 - acc: 0.9619\n",
      "Epoch 464/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5078 - acc: 0.9619\n",
      "Epoch 465/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.5071 - acc: 0.9619\n",
      "Epoch 466/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.5064 - acc: 0.9619\n",
      "Epoch 467/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.5057 - acc: 0.9619\n",
      "Epoch 468/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.5050 - acc: 0.9619\n",
      "Epoch 469/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.5043 - acc: 0.9619\n",
      "Epoch 470/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5036 - acc: 0.9619\n",
      "Epoch 471/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.5029 - acc: 0.9619\n",
      "Epoch 472/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.5022 - acc: 0.9619\n",
      "Epoch 473/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.5015 - acc: 0.9619\n",
      "Epoch 474/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.5008 - acc: 0.9619\n",
      "Epoch 475/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.5001 - acc: 0.9619\n",
      "Epoch 476/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4994 - acc: 0.9619\n",
      "Epoch 477/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4987 - acc: 0.9619\n",
      "Epoch 478/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4980 - acc: 0.9619\n",
      "Epoch 479/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4973 - acc: 0.9619\n",
      "Epoch 480/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4967 - acc: 0.9619\n",
      "Epoch 481/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.4960 - acc: 0.9619\n",
      "Epoch 482/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4953 - acc: 0.9714\n",
      "Epoch 483/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4946 - acc: 0.9714\n",
      "Epoch 484/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4939 - acc: 0.9714\n",
      "Epoch 485/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4932 - acc: 0.9714\n",
      "Epoch 486/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4925 - acc: 0.9714\n",
      "Epoch 487/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4918 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.4911 - acc: 0.9714\n",
      "Epoch 489/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.4904 - acc: 0.9714\n",
      "Epoch 490/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.4898 - acc: 0.9714\n",
      "Epoch 491/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.4891 - acc: 0.9714\n",
      "Epoch 492/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4884 - acc: 0.9714\n",
      "Epoch 493/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4877 - acc: 0.9714\n",
      "Epoch 494/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.4870 - acc: 0.9714\n",
      "Epoch 495/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4863 - acc: 0.9714\n",
      "Epoch 496/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4856 - acc: 0.9714\n",
      "Epoch 497/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4850 - acc: 0.9714\n",
      "Epoch 498/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.4843 - acc: 0.9714\n",
      "Epoch 499/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4836 - acc: 0.9714\n",
      "Epoch 500/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4829 - acc: 0.9714\n",
      "Epoch 501/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4822 - acc: 0.9714\n",
      "Epoch 502/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.4815 - acc: 0.9714\n",
      "Epoch 503/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4809 - acc: 0.9714\n",
      "Epoch 504/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4802 - acc: 0.9714\n",
      "Epoch 505/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4795 - acc: 0.9714\n",
      "Epoch 506/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4788 - acc: 0.9714\n",
      "Epoch 507/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4781 - acc: 0.9714\n",
      "Epoch 508/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.4775 - acc: 0.9714\n",
      "Epoch 509/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.4768 - acc: 0.9714\n",
      "Epoch 510/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4761 - acc: 0.9714\n",
      "Epoch 511/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.4754 - acc: 0.9714\n",
      "Epoch 512/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4748 - acc: 0.9714\n",
      "Epoch 513/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4741 - acc: 0.9714\n",
      "Epoch 514/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4734 - acc: 0.9714\n",
      "Epoch 515/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4727 - acc: 0.9714\n",
      "Epoch 516/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4721 - acc: 0.9714\n",
      "Epoch 517/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.4714 - acc: 0.9714\n",
      "Epoch 518/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.4707 - acc: 0.9714\n",
      "Epoch 519/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4700 - acc: 0.9714\n",
      "Epoch 520/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4694 - acc: 0.9714\n",
      "Epoch 521/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4687 - acc: 0.9714\n",
      "Epoch 522/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.4680 - acc: 0.9714\n",
      "Epoch 523/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4673 - acc: 0.9714\n",
      "Epoch 524/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4667 - acc: 0.9714\n",
      "Epoch 525/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4660 - acc: 0.9714\n",
      "Epoch 526/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.4653 - acc: 0.9619\n",
      "Epoch 527/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.4647 - acc: 0.9619\n",
      "Epoch 528/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.4640 - acc: 0.9619\n",
      "Epoch 529/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.4633 - acc: 0.9619\n",
      "Epoch 530/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4627 - acc: 0.9619\n",
      "Epoch 531/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.4620 - acc: 0.9619\n",
      "Epoch 532/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4613 - acc: 0.9619\n",
      "Epoch 533/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4607 - acc: 0.9619\n",
      "Epoch 534/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4600 - acc: 0.9619\n",
      "Epoch 535/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4593 - acc: 0.9619\n",
      "Epoch 536/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4587 - acc: 0.9619\n",
      "Epoch 537/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.4580 - acc: 0.9619\n",
      "Epoch 538/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.4573 - acc: 0.9619\n",
      "Epoch 539/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4567 - acc: 0.9619\n",
      "Epoch 540/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4560 - acc: 0.9619\n",
      "Epoch 541/2000\n",
      "105/105 [==============================] - 0s 36us/step - loss: 0.4554 - acc: 0.9619\n",
      "Epoch 542/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4547 - acc: 0.9619\n",
      "Epoch 543/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4540 - acc: 0.9619\n",
      "Epoch 544/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.4534 - acc: 0.9619\n",
      "Epoch 545/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4527 - acc: 0.9619\n",
      "Epoch 546/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4521 - acc: 0.9619\n",
      "Epoch 547/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4514 - acc: 0.9619\n",
      "Epoch 548/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.4507 - acc: 0.9619\n",
      "Epoch 549/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4501 - acc: 0.9619\n",
      "Epoch 550/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4494 - acc: 0.9619\n",
      "Epoch 551/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4488 - acc: 0.9619\n",
      "Epoch 552/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4481 - acc: 0.9619\n",
      "Epoch 553/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4475 - acc: 0.9619\n",
      "Epoch 554/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4468 - acc: 0.9619\n",
      "Epoch 555/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4462 - acc: 0.9619\n",
      "Epoch 556/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.4455 - acc: 0.9619\n",
      "Epoch 557/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4449 - acc: 0.9619\n",
      "Epoch 558/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.4442 - acc: 0.9619\n",
      "Epoch 559/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4436 - acc: 0.9619\n",
      "Epoch 560/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4429 - acc: 0.9619\n",
      "Epoch 561/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4423 - acc: 0.9619\n",
      "Epoch 562/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4416 - acc: 0.9619\n",
      "Epoch 563/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4410 - acc: 0.9619\n",
      "Epoch 564/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.4403 - acc: 0.9619\n",
      "Epoch 565/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4397 - acc: 0.9619\n",
      "Epoch 566/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4390 - acc: 0.9619\n",
      "Epoch 567/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.4384 - acc: 0.9619\n",
      "Epoch 568/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4377 - acc: 0.9619\n",
      "Epoch 569/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4371 - acc: 0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.4364 - acc: 0.9619\n",
      "Epoch 571/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4358 - acc: 0.9619\n",
      "Epoch 572/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4351 - acc: 0.9619\n",
      "Epoch 573/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4345 - acc: 0.9619\n",
      "Epoch 574/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4338 - acc: 0.9619\n",
      "Epoch 575/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4332 - acc: 0.9619\n",
      "Epoch 576/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.4326 - acc: 0.9619\n",
      "Epoch 577/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4319 - acc: 0.9619\n",
      "Epoch 578/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4313 - acc: 0.9619\n",
      "Epoch 579/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4306 - acc: 0.9619\n",
      "Epoch 580/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.4300 - acc: 0.9619\n",
      "Epoch 581/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.4294 - acc: 0.9619\n",
      "Epoch 582/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4287 - acc: 0.9619\n",
      "Epoch 583/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.4281 - acc: 0.9619\n",
      "Epoch 584/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4274 - acc: 0.9619\n",
      "Epoch 585/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.4268 - acc: 0.9619\n",
      "Epoch 586/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4262 - acc: 0.9619\n",
      "Epoch 587/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4255 - acc: 0.9619\n",
      "Epoch 588/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4249 - acc: 0.9619\n",
      "Epoch 589/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4243 - acc: 0.9619\n",
      "Epoch 590/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4236 - acc: 0.9619\n",
      "Epoch 591/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.4230 - acc: 0.9619\n",
      "Epoch 592/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4224 - acc: 0.9619\n",
      "Epoch 593/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4217 - acc: 0.9619\n",
      "Epoch 594/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.4211 - acc: 0.9619\n",
      "Epoch 595/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4205 - acc: 0.9619\n",
      "Epoch 596/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4198 - acc: 0.9619\n",
      "Epoch 597/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.4192 - acc: 0.9619\n",
      "Epoch 598/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4186 - acc: 0.9619\n",
      "Epoch 599/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.4179 - acc: 0.9619\n",
      "Epoch 600/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4173 - acc: 0.9619\n",
      "Epoch 601/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.4167 - acc: 0.9619\n",
      "Epoch 602/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.4160 - acc: 0.9619\n",
      "Epoch 603/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4154 - acc: 0.9619\n",
      "Epoch 604/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4148 - acc: 0.9619\n",
      "Epoch 605/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4142 - acc: 0.9619\n",
      "Epoch 606/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.4135 - acc: 0.9619\n",
      "Epoch 607/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4129 - acc: 0.9619\n",
      "Epoch 608/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.4123 - acc: 0.9619\n",
      "Epoch 609/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.4117 - acc: 0.9619\n",
      "Epoch 610/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4110 - acc: 0.9619\n",
      "Epoch 611/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.4104 - acc: 0.9619\n",
      "Epoch 612/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4098 - acc: 0.9619\n",
      "Epoch 613/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.4092 - acc: 0.9619\n",
      "Epoch 614/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.4085 - acc: 0.9619\n",
      "Epoch 615/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.4079 - acc: 0.9619\n",
      "Epoch 616/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4073 - acc: 0.9619\n",
      "Epoch 617/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4067 - acc: 0.9619\n",
      "Epoch 618/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.4061 - acc: 0.9619\n",
      "Epoch 619/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4054 - acc: 0.9619\n",
      "Epoch 620/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.4048 - acc: 0.9619\n",
      "Epoch 621/2000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.4042 - acc: 0.9619\n",
      "Epoch 622/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.4036 - acc: 0.9619\n",
      "Epoch 623/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.4030 - acc: 0.9619\n",
      "Epoch 624/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.4024 - acc: 0.9619\n",
      "Epoch 625/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.4017 - acc: 0.9619\n",
      "Epoch 626/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.4011 - acc: 0.9619\n",
      "Epoch 627/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.4005 - acc: 0.9619\n",
      "Epoch 628/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.3999 - acc: 0.9714\n",
      "Epoch 629/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3993 - acc: 0.9714\n",
      "Epoch 630/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.3987 - acc: 0.9714\n",
      "Epoch 631/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3981 - acc: 0.9714\n",
      "Epoch 632/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3975 - acc: 0.9714\n",
      "Epoch 633/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3968 - acc: 0.9714\n",
      "Epoch 634/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3962 - acc: 0.9714\n",
      "Epoch 635/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.3956 - acc: 0.9714\n",
      "Epoch 636/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.3950 - acc: 0.9714\n",
      "Epoch 637/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3944 - acc: 0.9714\n",
      "Epoch 638/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3938 - acc: 0.9714\n",
      "Epoch 639/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3932 - acc: 0.9714\n",
      "Epoch 640/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3926 - acc: 0.9714\n",
      "Epoch 641/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3920 - acc: 0.9714\n",
      "Epoch 642/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3914 - acc: 0.9714\n",
      "Epoch 643/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3908 - acc: 0.9714\n",
      "Epoch 644/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3902 - acc: 0.9714\n",
      "Epoch 645/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3895 - acc: 0.9714\n",
      "Epoch 646/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.3889 - acc: 0.9714\n",
      "Epoch 647/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.3883 - acc: 0.9714\n",
      "Epoch 648/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3877 - acc: 0.9714\n",
      "Epoch 649/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3871 - acc: 0.9714\n",
      "Epoch 650/2000\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.3865 - acc: 0.9714\n",
      "Epoch 651/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3859 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3853 - acc: 0.9714\n",
      "Epoch 653/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3847 - acc: 0.9714\n",
      "Epoch 654/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3841 - acc: 0.9714\n",
      "Epoch 655/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.3835 - acc: 0.9714\n",
      "Epoch 656/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.3829 - acc: 0.9714\n",
      "Epoch 657/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3823 - acc: 0.9714\n",
      "Epoch 658/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.3817 - acc: 0.9714\n",
      "Epoch 659/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3811 - acc: 0.9714\n",
      "Epoch 660/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3805 - acc: 0.9714\n",
      "Epoch 661/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3800 - acc: 0.9714\n",
      "Epoch 662/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3794 - acc: 0.9714\n",
      "Epoch 663/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3788 - acc: 0.9714\n",
      "Epoch 664/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3782 - acc: 0.9714\n",
      "Epoch 665/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3776 - acc: 0.9714\n",
      "Epoch 666/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3770 - acc: 0.9714\n",
      "Epoch 667/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3764 - acc: 0.9714\n",
      "Epoch 668/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.3758 - acc: 0.9714\n",
      "Epoch 669/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.3752 - acc: 0.9714\n",
      "Epoch 670/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3746 - acc: 0.9714\n",
      "Epoch 671/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.3740 - acc: 0.9714\n",
      "Epoch 672/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3734 - acc: 0.9714\n",
      "Epoch 673/2000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.3729 - acc: 0.9714\n",
      "Epoch 674/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3723 - acc: 0.9714\n",
      "Epoch 675/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3717 - acc: 0.9714\n",
      "Epoch 676/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.3711 - acc: 0.9714\n",
      "Epoch 677/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3705 - acc: 0.9714\n",
      "Epoch 678/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3699 - acc: 0.9714\n",
      "Epoch 679/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.3693 - acc: 0.9714\n",
      "Epoch 680/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3688 - acc: 0.9714\n",
      "Epoch 681/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3682 - acc: 0.9714\n",
      "Epoch 682/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3676 - acc: 0.9714\n",
      "Epoch 683/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3670 - acc: 0.9714\n",
      "Epoch 684/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3664 - acc: 0.9714\n",
      "Epoch 685/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.3658 - acc: 0.9714\n",
      "Epoch 686/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3653 - acc: 0.9714\n",
      "Epoch 687/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3647 - acc: 0.9714\n",
      "Epoch 688/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.3641 - acc: 0.9714\n",
      "Epoch 689/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3635 - acc: 0.9714\n",
      "Epoch 690/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3630 - acc: 0.9714\n",
      "Epoch 691/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3624 - acc: 0.9714\n",
      "Epoch 692/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3618 - acc: 0.9714\n",
      "Epoch 693/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.3612 - acc: 0.9714\n",
      "Epoch 694/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.3607 - acc: 0.9714\n",
      "Epoch 695/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3601 - acc: 0.9714\n",
      "Epoch 696/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3595 - acc: 0.9714\n",
      "Epoch 697/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3589 - acc: 0.9714\n",
      "Epoch 698/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3584 - acc: 0.9714\n",
      "Epoch 699/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.3578 - acc: 0.9714\n",
      "Epoch 700/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.3572 - acc: 0.9714\n",
      "Epoch 701/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3567 - acc: 0.9714\n",
      "Epoch 702/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3561 - acc: 0.9714\n",
      "Epoch 703/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3555 - acc: 0.9714\n",
      "Epoch 704/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3549 - acc: 0.9714\n",
      "Epoch 705/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3544 - acc: 0.9714\n",
      "Epoch 706/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3538 - acc: 0.9714\n",
      "Epoch 707/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.3532 - acc: 0.9714\n",
      "Epoch 708/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3527 - acc: 0.9714\n",
      "Epoch 709/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.3521 - acc: 0.9714\n",
      "Epoch 710/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3516 - acc: 0.9714\n",
      "Epoch 711/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.3510 - acc: 0.9714\n",
      "Epoch 712/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.3504 - acc: 0.9714\n",
      "Epoch 713/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3499 - acc: 0.9714\n",
      "Epoch 714/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3493 - acc: 0.9714\n",
      "Epoch 715/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3487 - acc: 0.9714\n",
      "Epoch 716/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3482 - acc: 0.9714\n",
      "Epoch 717/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3476 - acc: 0.9714\n",
      "Epoch 718/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3471 - acc: 0.9714\n",
      "Epoch 719/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.3465 - acc: 0.9714\n",
      "Epoch 720/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3460 - acc: 0.9714\n",
      "Epoch 721/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.3454 - acc: 0.9714\n",
      "Epoch 722/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3448 - acc: 0.9714\n",
      "Epoch 723/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.3443 - acc: 0.9714\n",
      "Epoch 724/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3437 - acc: 0.9714\n",
      "Epoch 725/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.3432 - acc: 0.9714\n",
      "Epoch 726/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.3426 - acc: 0.9714\n",
      "Epoch 727/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3421 - acc: 0.9714\n",
      "Epoch 728/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3415 - acc: 0.9714\n",
      "Epoch 729/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3410 - acc: 0.9714\n",
      "Epoch 730/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3404 - acc: 0.9714\n",
      "Epoch 731/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3399 - acc: 0.9714\n",
      "Epoch 732/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.3393 - acc: 0.9714\n",
      "Epoch 733/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3388 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 734/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.3382 - acc: 0.9714\n",
      "Epoch 735/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3377 - acc: 0.9714\n",
      "Epoch 736/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3372 - acc: 0.9714\n",
      "Epoch 737/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3366 - acc: 0.9714\n",
      "Epoch 738/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3361 - acc: 0.9714\n",
      "Epoch 739/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3355 - acc: 0.9714\n",
      "Epoch 740/2000\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.3350 - acc: 0.9714\n",
      "Epoch 741/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3344 - acc: 0.9714\n",
      "Epoch 742/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3339 - acc: 0.9714\n",
      "Epoch 743/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.3334 - acc: 0.9714\n",
      "Epoch 744/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3328 - acc: 0.9714\n",
      "Epoch 745/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3323 - acc: 0.9714\n",
      "Epoch 746/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3317 - acc: 0.9714\n",
      "Epoch 747/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3312 - acc: 0.9714\n",
      "Epoch 748/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3307 - acc: 0.9714\n",
      "Epoch 749/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.3301 - acc: 0.9714\n",
      "Epoch 750/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3296 - acc: 0.9714\n",
      "Epoch 751/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3291 - acc: 0.9714\n",
      "Epoch 752/2000\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.3285 - acc: 0.9714\n",
      "Epoch 753/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.3280 - acc: 0.9714\n",
      "Epoch 754/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.3275 - acc: 0.9714\n",
      "Epoch 755/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.3269 - acc: 0.9714\n",
      "Epoch 756/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3264 - acc: 0.9714\n",
      "Epoch 757/2000\n",
      "105/105 [==============================] - 0s 37us/step - loss: 0.3259 - acc: 0.9714\n",
      "Epoch 758/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.3254 - acc: 0.9714\n",
      "Epoch 759/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.3248 - acc: 0.9714\n",
      "Epoch 760/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3243 - acc: 0.9714\n",
      "Epoch 761/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3238 - acc: 0.9714\n",
      "Epoch 762/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.3232 - acc: 0.9714\n",
      "Epoch 763/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3227 - acc: 0.9714\n",
      "Epoch 764/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3222 - acc: 0.9714\n",
      "Epoch 765/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3217 - acc: 0.9714\n",
      "Epoch 766/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3212 - acc: 0.9810\n",
      "Epoch 767/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3206 - acc: 0.9810\n",
      "Epoch 768/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.3201 - acc: 0.9810\n",
      "Epoch 769/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3196 - acc: 0.9810\n",
      "Epoch 770/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3191 - acc: 0.9810\n",
      "Epoch 771/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3186 - acc: 0.9810\n",
      "Epoch 772/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3180 - acc: 0.9810\n",
      "Epoch 773/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.3175 - acc: 0.9810\n",
      "Epoch 774/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.3170 - acc: 0.9810\n",
      "Epoch 775/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.3165 - acc: 0.9810\n",
      "Epoch 776/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3160 - acc: 0.9810\n",
      "Epoch 777/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.3155 - acc: 0.9810\n",
      "Epoch 778/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3150 - acc: 0.9810\n",
      "Epoch 779/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3144 - acc: 0.9810\n",
      "Epoch 780/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3139 - acc: 0.9810\n",
      "Epoch 781/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.3134 - acc: 0.9810\n",
      "Epoch 782/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3129 - acc: 0.9810\n",
      "Epoch 783/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3124 - acc: 0.9810\n",
      "Epoch 784/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.3119 - acc: 0.9810\n",
      "Epoch 785/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.3114 - acc: 0.9810\n",
      "Epoch 786/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3109 - acc: 0.9810\n",
      "Epoch 787/2000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.3104 - acc: 0.9810\n",
      "Epoch 788/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.3099 - acc: 0.9810\n",
      "Epoch 789/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.3094 - acc: 0.9810\n",
      "Epoch 790/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3089 - acc: 0.9810\n",
      "Epoch 791/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.3084 - acc: 0.9810\n",
      "Epoch 792/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3079 - acc: 0.9810\n",
      "Epoch 793/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.3074 - acc: 0.9810\n",
      "Epoch 794/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3069 - acc: 0.9810\n",
      "Epoch 795/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.3064 - acc: 0.9810\n",
      "Epoch 796/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.3059 - acc: 0.9810\n",
      "Epoch 797/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3054 - acc: 0.9714\n",
      "Epoch 798/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.3049 - acc: 0.9714\n",
      "Epoch 799/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.3044 - acc: 0.9714\n",
      "Epoch 800/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.3039 - acc: 0.9714\n",
      "Epoch 801/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.3034 - acc: 0.9714\n",
      "Epoch 802/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.3029 - acc: 0.9714\n",
      "Epoch 803/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3024 - acc: 0.9714\n",
      "Epoch 804/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.3019 - acc: 0.9714\n",
      "Epoch 805/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.3014 - acc: 0.9714\n",
      "Epoch 806/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.3010 - acc: 0.9714\n",
      "Epoch 807/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.3005 - acc: 0.9714\n",
      "Epoch 808/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.3000 - acc: 0.9714\n",
      "Epoch 809/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2995 - acc: 0.9714\n",
      "Epoch 810/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2990 - acc: 0.9714\n",
      "Epoch 811/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2985 - acc: 0.9714\n",
      "Epoch 812/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2980 - acc: 0.9714\n",
      "Epoch 813/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2976 - acc: 0.9714\n",
      "Epoch 814/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2971 - acc: 0.9714\n",
      "Epoch 815/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2966 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2961 - acc: 0.9714\n",
      "Epoch 817/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.2956 - acc: 0.9714\n",
      "Epoch 818/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2952 - acc: 0.9714\n",
      "Epoch 819/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2947 - acc: 0.9714\n",
      "Epoch 820/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2942 - acc: 0.9714\n",
      "Epoch 821/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2937 - acc: 0.9714\n",
      "Epoch 822/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2933 - acc: 0.9714\n",
      "Epoch 823/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2928 - acc: 0.9714\n",
      "Epoch 824/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2923 - acc: 0.9714\n",
      "Epoch 825/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2918 - acc: 0.9714\n",
      "Epoch 826/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.2914 - acc: 0.9714\n",
      "Epoch 827/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.2909 - acc: 0.9714\n",
      "Epoch 828/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2904 - acc: 0.9714\n",
      "Epoch 829/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2900 - acc: 0.9714\n",
      "Epoch 830/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2895 - acc: 0.9714\n",
      "Epoch 831/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2890 - acc: 0.9714\n",
      "Epoch 832/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2885 - acc: 0.9714\n",
      "Epoch 833/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2881 - acc: 0.9714\n",
      "Epoch 834/2000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.2876 - acc: 0.9714\n",
      "Epoch 835/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2872 - acc: 0.9714\n",
      "Epoch 836/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2867 - acc: 0.9714\n",
      "Epoch 837/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2862 - acc: 0.9714\n",
      "Epoch 838/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2858 - acc: 0.9714\n",
      "Epoch 839/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2853 - acc: 0.9714\n",
      "Epoch 840/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2849 - acc: 0.9714\n",
      "Epoch 841/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2844 - acc: 0.9714\n",
      "Epoch 842/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2839 - acc: 0.9714\n",
      "Epoch 843/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2835 - acc: 0.9714\n",
      "Epoch 844/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2830 - acc: 0.9714\n",
      "Epoch 845/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2826 - acc: 0.9714\n",
      "Epoch 846/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2821 - acc: 0.9714\n",
      "Epoch 847/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2817 - acc: 0.9714\n",
      "Epoch 848/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2812 - acc: 0.9714\n",
      "Epoch 849/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2808 - acc: 0.9714\n",
      "Epoch 850/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2803 - acc: 0.9714\n",
      "Epoch 851/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2799 - acc: 0.9714\n",
      "Epoch 852/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2794 - acc: 0.9714\n",
      "Epoch 853/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2790 - acc: 0.9714\n",
      "Epoch 854/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2786 - acc: 0.9714\n",
      "Epoch 855/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2781 - acc: 0.9714\n",
      "Epoch 856/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.2777 - acc: 0.9714\n",
      "Epoch 857/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2772 - acc: 0.9714\n",
      "Epoch 858/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2768 - acc: 0.9714\n",
      "Epoch 859/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2764 - acc: 0.9714\n",
      "Epoch 860/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2759 - acc: 0.9714\n",
      "Epoch 861/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2755 - acc: 0.9714\n",
      "Epoch 862/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2751 - acc: 0.9714\n",
      "Epoch 863/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2746 - acc: 0.9714\n",
      "Epoch 864/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2742 - acc: 0.9714\n",
      "Epoch 865/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2738 - acc: 0.9714\n",
      "Epoch 866/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.2733 - acc: 0.9714\n",
      "Epoch 867/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2729 - acc: 0.9714\n",
      "Epoch 868/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2725 - acc: 0.9714\n",
      "Epoch 869/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2720 - acc: 0.9714\n",
      "Epoch 870/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2716 - acc: 0.9714\n",
      "Epoch 871/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2712 - acc: 0.9714\n",
      "Epoch 872/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2708 - acc: 0.9714\n",
      "Epoch 873/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.2704 - acc: 0.9810\n",
      "Epoch 874/2000\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.2699 - acc: 0.9714\n",
      "Epoch 875/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2695 - acc: 0.9714\n",
      "Epoch 876/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2691 - acc: 0.9714\n",
      "Epoch 877/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2687 - acc: 0.9714\n",
      "Epoch 878/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2683 - acc: 0.9714\n",
      "Epoch 879/2000\n",
      "105/105 [==============================] - 0s 72us/step - loss: 0.2678 - acc: 0.9714\n",
      "Epoch 880/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2674 - acc: 0.9810\n",
      "Epoch 881/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2670 - acc: 0.9810\n",
      "Epoch 882/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2666 - acc: 0.9810\n",
      "Epoch 883/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2662 - acc: 0.9810\n",
      "Epoch 884/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2658 - acc: 0.9810\n",
      "Epoch 885/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.2654 - acc: 0.9810\n",
      "Epoch 886/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2650 - acc: 0.9810\n",
      "Epoch 887/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2646 - acc: 0.9810\n",
      "Epoch 888/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2641 - acc: 0.9810\n",
      "Epoch 889/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2637 - acc: 0.9810\n",
      "Epoch 890/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2633 - acc: 0.9714\n",
      "Epoch 891/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2629 - acc: 0.9714\n",
      "Epoch 892/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2625 - acc: 0.9714\n",
      "Epoch 893/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2621 - acc: 0.9714\n",
      "Epoch 894/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2617 - acc: 0.9714\n",
      "Epoch 895/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2613 - acc: 0.9714\n",
      "Epoch 896/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2609 - acc: 0.9714\n",
      "Epoch 897/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2605 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2601 - acc: 0.9714\n",
      "Epoch 899/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2597 - acc: 0.9714\n",
      "Epoch 900/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2593 - acc: 0.9714\n",
      "Epoch 901/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2589 - acc: 0.9714\n",
      "Epoch 902/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2585 - acc: 0.9714\n",
      "Epoch 903/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2582 - acc: 0.9714\n",
      "Epoch 904/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2578 - acc: 0.9714\n",
      "Epoch 905/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2574 - acc: 0.9714\n",
      "Epoch 906/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.2570 - acc: 0.9714\n",
      "Epoch 907/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2566 - acc: 0.9714\n",
      "Epoch 908/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.2562 - acc: 0.9714\n",
      "Epoch 909/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2558 - acc: 0.9714\n",
      "Epoch 910/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2554 - acc: 0.9714\n",
      "Epoch 911/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2550 - acc: 0.9714\n",
      "Epoch 912/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.2546 - acc: 0.9714\n",
      "Epoch 913/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2543 - acc: 0.9714\n",
      "Epoch 914/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2539 - acc: 0.9714\n",
      "Epoch 915/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2535 - acc: 0.9714\n",
      "Epoch 916/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2531 - acc: 0.9714\n",
      "Epoch 917/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.2527 - acc: 0.9714\n",
      "Epoch 918/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.2524 - acc: 0.9714\n",
      "Epoch 919/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2520 - acc: 0.9714\n",
      "Epoch 920/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2516 - acc: 0.9714\n",
      "Epoch 921/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2512 - acc: 0.9714\n",
      "Epoch 922/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.2508 - acc: 0.9714\n",
      "Epoch 923/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2505 - acc: 0.9714\n",
      "Epoch 924/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2501 - acc: 0.9714\n",
      "Epoch 925/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2497 - acc: 0.9714\n",
      "Epoch 926/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2493 - acc: 0.9714\n",
      "Epoch 927/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2490 - acc: 0.9714\n",
      "Epoch 928/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2486 - acc: 0.9714\n",
      "Epoch 929/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2482 - acc: 0.9714\n",
      "Epoch 930/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2479 - acc: 0.9714\n",
      "Epoch 931/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2475 - acc: 0.9714\n",
      "Epoch 932/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2471 - acc: 0.9714\n",
      "Epoch 933/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.2467 - acc: 0.9714\n",
      "Epoch 934/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2464 - acc: 0.9714\n",
      "Epoch 935/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2460 - acc: 0.9714\n",
      "Epoch 936/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2456 - acc: 0.9714\n",
      "Epoch 937/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2453 - acc: 0.9714\n",
      "Epoch 938/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2449 - acc: 0.9714\n",
      "Epoch 939/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2446 - acc: 0.9714\n",
      "Epoch 940/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2442 - acc: 0.9714\n",
      "Epoch 941/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2438 - acc: 0.9714\n",
      "Epoch 942/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2435 - acc: 0.9714\n",
      "Epoch 943/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2431 - acc: 0.9714\n",
      "Epoch 944/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2427 - acc: 0.9714\n",
      "Epoch 945/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2424 - acc: 0.9714\n",
      "Epoch 946/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2420 - acc: 0.9714\n",
      "Epoch 947/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2417 - acc: 0.9714\n",
      "Epoch 948/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.2413 - acc: 0.9714\n",
      "Epoch 949/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2410 - acc: 0.9714\n",
      "Epoch 950/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2406 - acc: 0.9714\n",
      "Epoch 951/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2403 - acc: 0.9714\n",
      "Epoch 952/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.2399 - acc: 0.9714\n",
      "Epoch 953/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2396 - acc: 0.9714\n",
      "Epoch 954/2000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.2392 - acc: 0.9714\n",
      "Epoch 955/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2389 - acc: 0.9714\n",
      "Epoch 956/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2385 - acc: 0.9714\n",
      "Epoch 957/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.2382 - acc: 0.9714\n",
      "Epoch 958/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2378 - acc: 0.9714\n",
      "Epoch 959/2000\n",
      "105/105 [==============================] - 0s 120us/step - loss: 0.2375 - acc: 0.9714\n",
      "Epoch 960/2000\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.2371 - acc: 0.9714\n",
      "Epoch 961/2000\n",
      "105/105 [==============================] - 0s 179us/step - loss: 0.2368 - acc: 0.9714\n",
      "Epoch 962/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.2364 - acc: 0.9714\n",
      "Epoch 963/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2361 - acc: 0.9714\n",
      "Epoch 964/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2357 - acc: 0.9714\n",
      "Epoch 965/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2354 - acc: 0.9714\n",
      "Epoch 966/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2351 - acc: 0.9714\n",
      "Epoch 967/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2347 - acc: 0.9714\n",
      "Epoch 968/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2344 - acc: 0.9714\n",
      "Epoch 969/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2340 - acc: 0.9714\n",
      "Epoch 970/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2337 - acc: 0.9714\n",
      "Epoch 971/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2334 - acc: 0.9714\n",
      "Epoch 972/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2330 - acc: 0.9714\n",
      "Epoch 973/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.2327 - acc: 0.9714\n",
      "Epoch 974/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2323 - acc: 0.9714\n",
      "Epoch 975/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2320 - acc: 0.9714\n",
      "Epoch 976/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2317 - acc: 0.9714\n",
      "Epoch 977/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2313 - acc: 0.9714\n",
      "Epoch 978/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.2310 - acc: 0.9714\n",
      "Epoch 979/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2307 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2304 - acc: 0.9714\n",
      "Epoch 981/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2300 - acc: 0.9714\n",
      "Epoch 982/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2297 - acc: 0.9714\n",
      "Epoch 983/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2294 - acc: 0.9714\n",
      "Epoch 984/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2290 - acc: 0.9714\n",
      "Epoch 985/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2287 - acc: 0.9714\n",
      "Epoch 986/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2284 - acc: 0.9714\n",
      "Epoch 987/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2281 - acc: 0.9714\n",
      "Epoch 988/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2277 - acc: 0.9714\n",
      "Epoch 989/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2274 - acc: 0.9714\n",
      "Epoch 990/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2271 - acc: 0.9714\n",
      "Epoch 991/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2268 - acc: 0.9714\n",
      "Epoch 992/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2264 - acc: 0.9714\n",
      "Epoch 993/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2261 - acc: 0.9714\n",
      "Epoch 994/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2258 - acc: 0.9714\n",
      "Epoch 995/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2255 - acc: 0.9714\n",
      "Epoch 996/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.2252 - acc: 0.9714\n",
      "Epoch 997/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2249 - acc: 0.9714\n",
      "Epoch 998/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2245 - acc: 0.9714\n",
      "Epoch 999/2000\n",
      "105/105 [==============================] - 0s 117us/step - loss: 0.2242 - acc: 0.9714\n",
      "Epoch 1000/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2239 - acc: 0.9714\n",
      "Epoch 1001/2000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.2236 - acc: 0.9714\n",
      "Epoch 1002/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2233 - acc: 0.9714\n",
      "Epoch 1003/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2230 - acc: 0.9714\n",
      "Epoch 1004/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.2227 - acc: 0.9714\n",
      "Epoch 1005/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2223 - acc: 0.9714\n",
      "Epoch 1006/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2220 - acc: 0.9714\n",
      "Epoch 1007/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2217 - acc: 0.9714\n",
      "Epoch 1008/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2214 - acc: 0.9714\n",
      "Epoch 1009/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2211 - acc: 0.9714\n",
      "Epoch 1010/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2208 - acc: 0.9714\n",
      "Epoch 1011/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.2205 - acc: 0.9714\n",
      "Epoch 1012/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.2202 - acc: 0.9714\n",
      "Epoch 1013/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.2199 - acc: 0.9714\n",
      "Epoch 1014/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2196 - acc: 0.9714\n",
      "Epoch 1015/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2193 - acc: 0.9714\n",
      "Epoch 1016/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.2190 - acc: 0.9714\n",
      "Epoch 1017/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2187 - acc: 0.9714\n",
      "Epoch 1018/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2184 - acc: 0.9714\n",
      "Epoch 1019/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2181 - acc: 0.9714\n",
      "Epoch 1020/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2178 - acc: 0.9714\n",
      "Epoch 1021/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.2175 - acc: 0.9714\n",
      "Epoch 1022/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2172 - acc: 0.9714\n",
      "Epoch 1023/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2169 - acc: 0.9714\n",
      "Epoch 1024/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2166 - acc: 0.9714\n",
      "Epoch 1025/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2163 - acc: 0.9714\n",
      "Epoch 1026/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.2160 - acc: 0.9714\n",
      "Epoch 1027/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2157 - acc: 0.9714\n",
      "Epoch 1028/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2154 - acc: 0.9714\n",
      "Epoch 1029/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2151 - acc: 0.9714\n",
      "Epoch 1030/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2148 - acc: 0.9714\n",
      "Epoch 1031/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.2145 - acc: 0.9714\n",
      "Epoch 1032/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.2142 - acc: 0.9714\n",
      "Epoch 1033/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2140 - acc: 0.9714\n",
      "Epoch 1034/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.2137 - acc: 0.9714\n",
      "Epoch 1035/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2134 - acc: 0.9714\n",
      "Epoch 1036/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2131 - acc: 0.9714\n",
      "Epoch 1037/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2128 - acc: 0.9714\n",
      "Epoch 1038/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.2125 - acc: 0.9714\n",
      "Epoch 1039/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2122 - acc: 0.9714\n",
      "Epoch 1040/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.2120 - acc: 0.9714\n",
      "Epoch 1041/2000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.2117 - acc: 0.9714\n",
      "Epoch 1042/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2114 - acc: 0.9714\n",
      "Epoch 1043/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.2111 - acc: 0.9714\n",
      "Epoch 1044/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2108 - acc: 0.9714\n",
      "Epoch 1045/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2106 - acc: 0.9714\n",
      "Epoch 1046/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.2103 - acc: 0.9714\n",
      "Epoch 1047/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2100 - acc: 0.9714\n",
      "Epoch 1048/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.2097 - acc: 0.9714\n",
      "Epoch 1049/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2094 - acc: 0.9714\n",
      "Epoch 1050/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2092 - acc: 0.9714\n",
      "Epoch 1051/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2089 - acc: 0.9714\n",
      "Epoch 1052/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.2086 - acc: 0.9714\n",
      "Epoch 1053/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.2083 - acc: 0.9714\n",
      "Epoch 1054/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.2081 - acc: 0.9714\n",
      "Epoch 1055/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2078 - acc: 0.9714\n",
      "Epoch 1056/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2075 - acc: 0.9714\n",
      "Epoch 1057/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2073 - acc: 0.9714\n",
      "Epoch 1058/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.2070 - acc: 0.9714\n",
      "Epoch 1059/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.2067 - acc: 0.9714\n",
      "Epoch 1060/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.2064 - acc: 0.9714\n",
      "Epoch 1061/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.2062 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1062/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2059 - acc: 0.9714\n",
      "Epoch 1063/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2056 - acc: 0.9714\n",
      "Epoch 1064/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.2054 - acc: 0.9714\n",
      "Epoch 1065/2000\n",
      "105/105 [==============================] - 0s 37us/step - loss: 0.2051 - acc: 0.9714\n",
      "Epoch 1066/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2049 - acc: 0.9714\n",
      "Epoch 1067/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2046 - acc: 0.9714\n",
      "Epoch 1068/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2043 - acc: 0.9714\n",
      "Epoch 1069/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.2041 - acc: 0.9714\n",
      "Epoch 1070/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2038 - acc: 0.9714\n",
      "Epoch 1071/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2035 - acc: 0.9714\n",
      "Epoch 1072/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.2033 - acc: 0.9714\n",
      "Epoch 1073/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.2030 - acc: 0.9714\n",
      "Epoch 1074/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2028 - acc: 0.9714\n",
      "Epoch 1075/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2025 - acc: 0.9714\n",
      "Epoch 1076/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.2023 - acc: 0.9714\n",
      "Epoch 1077/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.2020 - acc: 0.9714\n",
      "Epoch 1078/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.9714\n",
      "Epoch 1079/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2015 - acc: 0.9714\n",
      "Epoch 1080/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.9714\n",
      "Epoch 1081/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.2010 - acc: 0.9714\n",
      "Epoch 1082/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.2007 - acc: 0.9714\n",
      "Epoch 1083/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.2005 - acc: 0.9714\n",
      "Epoch 1084/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.2002 - acc: 0.9714\n",
      "Epoch 1085/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.2000 - acc: 0.9714\n",
      "Epoch 1086/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1997 - acc: 0.9714\n",
      "Epoch 1087/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1995 - acc: 0.9714\n",
      "Epoch 1088/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1992 - acc: 0.9714\n",
      "Epoch 1089/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1990 - acc: 0.9714\n",
      "Epoch 1090/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1987 - acc: 0.9714\n",
      "Epoch 1091/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1985 - acc: 0.9714\n",
      "Epoch 1092/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.1982 - acc: 0.9714\n",
      "Epoch 1093/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1980 - acc: 0.9714\n",
      "Epoch 1094/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1977 - acc: 0.9714\n",
      "Epoch 1095/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1975 - acc: 0.9714\n",
      "Epoch 1096/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1972 - acc: 0.9714\n",
      "Epoch 1097/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1970 - acc: 0.9714\n",
      "Epoch 1098/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1968 - acc: 0.9714\n",
      "Epoch 1099/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1965 - acc: 0.9714\n",
      "Epoch 1100/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1963 - acc: 0.9714\n",
      "Epoch 1101/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1960 - acc: 0.9714\n",
      "Epoch 1102/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1958 - acc: 0.9714\n",
      "Epoch 1103/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1956 - acc: 0.9714\n",
      "Epoch 1104/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1953 - acc: 0.9714\n",
      "Epoch 1105/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1951 - acc: 0.9714\n",
      "Epoch 1106/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1948 - acc: 0.9714\n",
      "Epoch 1107/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1946 - acc: 0.9714\n",
      "Epoch 1108/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1944 - acc: 0.9714\n",
      "Epoch 1109/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1941 - acc: 0.9714\n",
      "Epoch 1110/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1939 - acc: 0.9714\n",
      "Epoch 1111/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1937 - acc: 0.9714\n",
      "Epoch 1112/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1934 - acc: 0.9714\n",
      "Epoch 1113/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1932 - acc: 0.9714\n",
      "Epoch 1114/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1929 - acc: 0.9714\n",
      "Epoch 1115/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1927 - acc: 0.9714\n",
      "Epoch 1116/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1925 - acc: 0.9714\n",
      "Epoch 1117/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1923 - acc: 0.9714\n",
      "Epoch 1118/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1920 - acc: 0.9714\n",
      "Epoch 1119/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1918 - acc: 0.9714\n",
      "Epoch 1120/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1916 - acc: 0.9714\n",
      "Epoch 1121/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1913 - acc: 0.9714\n",
      "Epoch 1122/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1911 - acc: 0.9714\n",
      "Epoch 1123/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1909 - acc: 0.9714\n",
      "Epoch 1124/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1906 - acc: 0.9714\n",
      "Epoch 1125/2000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.1904 - acc: 0.9714\n",
      "Epoch 1126/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1902 - acc: 0.9714\n",
      "Epoch 1127/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1900 - acc: 0.9714\n",
      "Epoch 1128/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1897 - acc: 0.9714\n",
      "Epoch 1129/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1895 - acc: 0.9714\n",
      "Epoch 1130/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1893 - acc: 0.9714\n",
      "Epoch 1131/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1891 - acc: 0.9714\n",
      "Epoch 1132/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1888 - acc: 0.9714\n",
      "Epoch 1133/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1886 - acc: 0.9714\n",
      "Epoch 1134/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1884 - acc: 0.9714\n",
      "Epoch 1135/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1882 - acc: 0.9714\n",
      "Epoch 1136/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1880 - acc: 0.9714\n",
      "Epoch 1137/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1877 - acc: 0.9714\n",
      "Epoch 1138/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1875 - acc: 0.9714\n",
      "Epoch 1139/2000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.1873 - acc: 0.9714\n",
      "Epoch 1140/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1871 - acc: 0.9714\n",
      "Epoch 1141/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1869 - acc: 0.9714\n",
      "Epoch 1142/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1866 - acc: 0.9714\n",
      "Epoch 1143/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 50us/step - loss: 0.1864 - acc: 0.9714\n",
      "Epoch 1144/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1862 - acc: 0.9714\n",
      "Epoch 1145/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1860 - acc: 0.9714\n",
      "Epoch 1146/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1858 - acc: 0.9714\n",
      "Epoch 1147/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1856 - acc: 0.9714\n",
      "Epoch 1148/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1853 - acc: 0.9714\n",
      "Epoch 1149/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1851 - acc: 0.9714\n",
      "Epoch 1150/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1849 - acc: 0.9714\n",
      "Epoch 1151/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1847 - acc: 0.9714\n",
      "Epoch 1152/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1845 - acc: 0.9714\n",
      "Epoch 1153/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1843 - acc: 0.9714\n",
      "Epoch 1154/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1841 - acc: 0.9714\n",
      "Epoch 1155/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1839 - acc: 0.9714\n",
      "Epoch 1156/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1836 - acc: 0.9714\n",
      "Epoch 1157/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1834 - acc: 0.9714\n",
      "Epoch 1158/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1832 - acc: 0.9714\n",
      "Epoch 1159/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1830 - acc: 0.9714\n",
      "Epoch 1160/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1828 - acc: 0.9714\n",
      "Epoch 1161/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1826 - acc: 0.9714\n",
      "Epoch 1162/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1824 - acc: 0.9714\n",
      "Epoch 1163/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1822 - acc: 0.9714\n",
      "Epoch 1164/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1820 - acc: 0.9714\n",
      "Epoch 1165/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1818 - acc: 0.9714\n",
      "Epoch 1166/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1816 - acc: 0.9714\n",
      "Epoch 1167/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1814 - acc: 0.9714\n",
      "Epoch 1168/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1812 - acc: 0.9714\n",
      "Epoch 1169/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1810 - acc: 0.9714\n",
      "Epoch 1170/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1808 - acc: 0.9714\n",
      "Epoch 1171/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1805 - acc: 0.9714\n",
      "Epoch 1172/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1803 - acc: 0.9714\n",
      "Epoch 1173/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1801 - acc: 0.9714\n",
      "Epoch 1174/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1799 - acc: 0.9714\n",
      "Epoch 1175/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1797 - acc: 0.9714\n",
      "Epoch 1176/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1795 - acc: 0.9714\n",
      "Epoch 1177/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1793 - acc: 0.9714\n",
      "Epoch 1178/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1791 - acc: 0.9714\n",
      "Epoch 1179/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1789 - acc: 0.9714\n",
      "Epoch 1180/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1787 - acc: 0.9714\n",
      "Epoch 1181/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1785 - acc: 0.9714\n",
      "Epoch 1182/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1784 - acc: 0.9714\n",
      "Epoch 1183/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1782 - acc: 0.9714\n",
      "Epoch 1184/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1780 - acc: 0.9714\n",
      "Epoch 1185/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1778 - acc: 0.9714\n",
      "Epoch 1186/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1776 - acc: 0.9714\n",
      "Epoch 1187/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1774 - acc: 0.9714\n",
      "Epoch 1188/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1772 - acc: 0.9714\n",
      "Epoch 1189/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1770 - acc: 0.9714\n",
      "Epoch 1190/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1768 - acc: 0.9714\n",
      "Epoch 1191/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1766 - acc: 0.9714\n",
      "Epoch 1192/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1764 - acc: 0.9714\n",
      "Epoch 1193/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1762 - acc: 0.9714\n",
      "Epoch 1194/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1760 - acc: 0.9714\n",
      "Epoch 1195/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1758 - acc: 0.9714\n",
      "Epoch 1196/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1756 - acc: 0.9714\n",
      "Epoch 1197/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1754 - acc: 0.9714\n",
      "Epoch 1198/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1753 - acc: 0.9714\n",
      "Epoch 1199/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1751 - acc: 0.9714\n",
      "Epoch 1200/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1749 - acc: 0.9714\n",
      "Epoch 1201/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1747 - acc: 0.9714\n",
      "Epoch 1202/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1745 - acc: 0.9714\n",
      "Epoch 1203/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1743 - acc: 0.9714\n",
      "Epoch 1204/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1741 - acc: 0.9714\n",
      "Epoch 1205/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1739 - acc: 0.9714\n",
      "Epoch 1206/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1738 - acc: 0.9714\n",
      "Epoch 1207/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1736 - acc: 0.9714\n",
      "Epoch 1208/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1734 - acc: 0.9714\n",
      "Epoch 1209/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1732 - acc: 0.9714\n",
      "Epoch 1210/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1730 - acc: 0.9714\n",
      "Epoch 1211/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1728 - acc: 0.9714\n",
      "Epoch 1212/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1727 - acc: 0.9714\n",
      "Epoch 1213/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1725 - acc: 0.9714\n",
      "Epoch 1214/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1723 - acc: 0.9714\n",
      "Epoch 1215/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1721 - acc: 0.9714\n",
      "Epoch 1216/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1719 - acc: 0.9714\n",
      "Epoch 1217/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1717 - acc: 0.9714\n",
      "Epoch 1218/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1716 - acc: 0.9714\n",
      "Epoch 1219/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1714 - acc: 0.9714\n",
      "Epoch 1220/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1712 - acc: 0.9714\n",
      "Epoch 1221/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1710 - acc: 0.9714\n",
      "Epoch 1222/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1708 - acc: 0.9714\n",
      "Epoch 1223/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1707 - acc: 0.9714\n",
      "Epoch 1224/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1705 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1225/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.1703 - acc: 0.9714\n",
      "Epoch 1226/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1701 - acc: 0.9714\n",
      "Epoch 1227/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1700 - acc: 0.9714\n",
      "Epoch 1228/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1698 - acc: 0.9714\n",
      "Epoch 1229/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1696 - acc: 0.9714\n",
      "Epoch 1230/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1694 - acc: 0.9714\n",
      "Epoch 1231/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1693 - acc: 0.9714\n",
      "Epoch 1232/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1691 - acc: 0.9714\n",
      "Epoch 1233/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1689 - acc: 0.9714\n",
      "Epoch 1234/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1687 - acc: 0.9714\n",
      "Epoch 1235/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1686 - acc: 0.9714\n",
      "Epoch 1236/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1684 - acc: 0.9714\n",
      "Epoch 1237/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1682 - acc: 0.9714\n",
      "Epoch 1238/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1681 - acc: 0.9714\n",
      "Epoch 1239/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1679 - acc: 0.9714\n",
      "Epoch 1240/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1677 - acc: 0.9714\n",
      "Epoch 1241/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1675 - acc: 0.9714\n",
      "Epoch 1242/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1674 - acc: 0.9714\n",
      "Epoch 1243/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1672 - acc: 0.9714\n",
      "Epoch 1244/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1670 - acc: 0.9714\n",
      "Epoch 1245/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1669 - acc: 0.9714\n",
      "Epoch 1246/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1667 - acc: 0.9714\n",
      "Epoch 1247/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1665 - acc: 0.9714\n",
      "Epoch 1248/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1664 - acc: 0.9714\n",
      "Epoch 1249/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1662 - acc: 0.9714\n",
      "Epoch 1250/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1660 - acc: 0.9714\n",
      "Epoch 1251/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1659 - acc: 0.9714\n",
      "Epoch 1252/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1657 - acc: 0.9714\n",
      "Epoch 1253/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1655 - acc: 0.9714\n",
      "Epoch 1254/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1654 - acc: 0.9714\n",
      "Epoch 1255/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1652 - acc: 0.9714\n",
      "Epoch 1256/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1651 - acc: 0.9714\n",
      "Epoch 1257/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1649 - acc: 0.9714\n",
      "Epoch 1258/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1647 - acc: 0.9714\n",
      "Epoch 1259/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1646 - acc: 0.9714\n",
      "Epoch 1260/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1644 - acc: 0.9714\n",
      "Epoch 1261/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1642 - acc: 0.9714\n",
      "Epoch 1262/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1641 - acc: 0.9714\n",
      "Epoch 1263/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1639 - acc: 0.9714\n",
      "Epoch 1264/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1638 - acc: 0.9714\n",
      "Epoch 1265/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1636 - acc: 0.9714\n",
      "Epoch 1266/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1634 - acc: 0.9714\n",
      "Epoch 1267/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1633 - acc: 0.9714\n",
      "Epoch 1268/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1631 - acc: 0.9714\n",
      "Epoch 1269/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1630 - acc: 0.9714\n",
      "Epoch 1270/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1628 - acc: 0.9714\n",
      "Epoch 1271/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1626 - acc: 0.9714\n",
      "Epoch 1272/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1625 - acc: 0.9714\n",
      "Epoch 1273/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1623 - acc: 0.9714\n",
      "Epoch 1274/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1622 - acc: 0.9714\n",
      "Epoch 1275/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1620 - acc: 0.9714\n",
      "Epoch 1276/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1619 - acc: 0.9714\n",
      "Epoch 1277/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1617 - acc: 0.9714\n",
      "Epoch 1278/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1616 - acc: 0.9714\n",
      "Epoch 1279/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1614 - acc: 0.9714\n",
      "Epoch 1280/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1613 - acc: 0.9714\n",
      "Epoch 1281/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1611 - acc: 0.9714\n",
      "Epoch 1282/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1609 - acc: 0.9714\n",
      "Epoch 1283/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1608 - acc: 0.9714\n",
      "Epoch 1284/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1606 - acc: 0.9714\n",
      "Epoch 1285/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1605 - acc: 0.9714\n",
      "Epoch 1286/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1603 - acc: 0.9714\n",
      "Epoch 1287/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1602 - acc: 0.9714\n",
      "Epoch 1288/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1600 - acc: 0.9714\n",
      "Epoch 1289/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1599 - acc: 0.9714\n",
      "Epoch 1290/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1597 - acc: 0.9714\n",
      "Epoch 1291/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1596 - acc: 0.9714\n",
      "Epoch 1292/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1595 - acc: 0.9714\n",
      "Epoch 1293/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1593 - acc: 0.9714\n",
      "Epoch 1294/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1591 - acc: 0.9714\n",
      "Epoch 1295/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1590 - acc: 0.9714\n",
      "Epoch 1296/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1589 - acc: 0.9714\n",
      "Epoch 1297/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1587 - acc: 0.9714\n",
      "Epoch 1298/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1586 - acc: 0.9714\n",
      "Epoch 1299/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1584 - acc: 0.9714\n",
      "Epoch 1300/2000\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.1583 - acc: 0.9714\n",
      "Epoch 1301/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1581 - acc: 0.9714\n",
      "Epoch 1302/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1580 - acc: 0.9714\n",
      "Epoch 1303/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1578 - acc: 0.9714\n",
      "Epoch 1304/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1577 - acc: 0.9714\n",
      "Epoch 1305/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.1575 - acc: 0.9714\n",
      "Epoch 1306/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 48us/step - loss: 0.1574 - acc: 0.9714\n",
      "Epoch 1307/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1573 - acc: 0.9714\n",
      "Epoch 1308/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1571 - acc: 0.9714\n",
      "Epoch 1309/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1570 - acc: 0.9714\n",
      "Epoch 1310/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1568 - acc: 0.9714\n",
      "Epoch 1311/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1567 - acc: 0.9714\n",
      "Epoch 1312/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1565 - acc: 0.9714\n",
      "Epoch 1313/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1564 - acc: 0.9714\n",
      "Epoch 1314/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1563 - acc: 0.9714\n",
      "Epoch 1315/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1561 - acc: 0.9714\n",
      "Epoch 1316/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1560 - acc: 0.9714\n",
      "Epoch 1317/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1558 - acc: 0.9714\n",
      "Epoch 1318/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1557 - acc: 0.9714\n",
      "Epoch 1319/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1556 - acc: 0.9714\n",
      "Epoch 1320/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1554 - acc: 0.9714\n",
      "Epoch 1321/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1553 - acc: 0.9714\n",
      "Epoch 1322/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1552 - acc: 0.9714\n",
      "Epoch 1323/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1550 - acc: 0.9714\n",
      "Epoch 1324/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1549 - acc: 0.9714\n",
      "Epoch 1325/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1547 - acc: 0.9714\n",
      "Epoch 1326/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1546 - acc: 0.9714\n",
      "Epoch 1327/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1545 - acc: 0.9714\n",
      "Epoch 1328/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1543 - acc: 0.9714\n",
      "Epoch 1329/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1542 - acc: 0.9714\n",
      "Epoch 1330/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1541 - acc: 0.9714\n",
      "Epoch 1331/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1539 - acc: 0.9714\n",
      "Epoch 1332/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1538 - acc: 0.9714\n",
      "Epoch 1333/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1537 - acc: 0.9714\n",
      "Epoch 1334/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1535 - acc: 0.9714\n",
      "Epoch 1335/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1534 - acc: 0.9714\n",
      "Epoch 1336/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1533 - acc: 0.9714\n",
      "Epoch 1337/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1531 - acc: 0.9714\n",
      "Epoch 1338/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1530 - acc: 0.9714\n",
      "Epoch 1339/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1529 - acc: 0.9714\n",
      "Epoch 1340/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1527 - acc: 0.9714\n",
      "Epoch 1341/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1526 - acc: 0.9714\n",
      "Epoch 1342/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1525 - acc: 0.9714\n",
      "Epoch 1343/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1523 - acc: 0.9714\n",
      "Epoch 1344/2000\n",
      "105/105 [==============================] - 0s 83us/step - loss: 0.1522 - acc: 0.9714\n",
      "Epoch 1345/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1521 - acc: 0.9714\n",
      "Epoch 1346/2000\n",
      "105/105 [==============================] - 0s 84us/step - loss: 0.1519 - acc: 0.9714\n",
      "Epoch 1347/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1518 - acc: 0.9714\n",
      "Epoch 1348/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1517 - acc: 0.9714\n",
      "Epoch 1349/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1516 - acc: 0.9714\n",
      "Epoch 1350/2000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.1514 - acc: 0.9714\n",
      "Epoch 1351/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1513 - acc: 0.9714\n",
      "Epoch 1352/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1512 - acc: 0.9714\n",
      "Epoch 1353/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1510 - acc: 0.9714\n",
      "Epoch 1354/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1509 - acc: 0.9714\n",
      "Epoch 1355/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1508 - acc: 0.9714\n",
      "Epoch 1356/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1507 - acc: 0.9714\n",
      "Epoch 1357/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1505 - acc: 0.9714\n",
      "Epoch 1358/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1504 - acc: 0.9714\n",
      "Epoch 1359/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1503 - acc: 0.9714\n",
      "Epoch 1360/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1501 - acc: 0.9714\n",
      "Epoch 1361/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1500 - acc: 0.9714\n",
      "Epoch 1362/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1499 - acc: 0.9714\n",
      "Epoch 1363/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1498 - acc: 0.9714\n",
      "Epoch 1364/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1496 - acc: 0.9714\n",
      "Epoch 1365/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1495 - acc: 0.9714\n",
      "Epoch 1366/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1494 - acc: 0.9714\n",
      "Epoch 1367/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1493 - acc: 0.9714\n",
      "Epoch 1368/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1491 - acc: 0.9714\n",
      "Epoch 1369/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1490 - acc: 0.9714\n",
      "Epoch 1370/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1489 - acc: 0.9714\n",
      "Epoch 1371/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1488 - acc: 0.9714\n",
      "Epoch 1372/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1487 - acc: 0.9714\n",
      "Epoch 1373/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1485 - acc: 0.9714\n",
      "Epoch 1374/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1484 - acc: 0.9714\n",
      "Epoch 1375/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1483 - acc: 0.9714\n",
      "Epoch 1376/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1482 - acc: 0.9714\n",
      "Epoch 1377/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1480 - acc: 0.9714\n",
      "Epoch 1378/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1479 - acc: 0.9714\n",
      "Epoch 1379/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1478 - acc: 0.9714\n",
      "Epoch 1380/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1477 - acc: 0.9714\n",
      "Epoch 1381/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1476 - acc: 0.9714\n",
      "Epoch 1382/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1474 - acc: 0.9714\n",
      "Epoch 1383/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1473 - acc: 0.9714\n",
      "Epoch 1384/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1472 - acc: 0.9714\n",
      "Epoch 1385/2000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.1471 - acc: 0.9714\n",
      "Epoch 1386/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1470 - acc: 0.9714\n",
      "Epoch 1387/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1468 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1388/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1467 - acc: 0.9714\n",
      "Epoch 1389/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1466 - acc: 0.9714\n",
      "Epoch 1390/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1465 - acc: 0.9714\n",
      "Epoch 1391/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1464 - acc: 0.9714\n",
      "Epoch 1392/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1463 - acc: 0.9714\n",
      "Epoch 1393/2000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.1461 - acc: 0.9714\n",
      "Epoch 1394/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1460 - acc: 0.9714\n",
      "Epoch 1395/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1459 - acc: 0.9714\n",
      "Epoch 1396/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1458 - acc: 0.9714\n",
      "Epoch 1397/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1457 - acc: 0.9714\n",
      "Epoch 1398/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1456 - acc: 0.9714\n",
      "Epoch 1399/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1454 - acc: 0.9714\n",
      "Epoch 1400/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1453 - acc: 0.9714\n",
      "Epoch 1401/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1452 - acc: 0.9714\n",
      "Epoch 1402/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1451 - acc: 0.9714\n",
      "Epoch 1403/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1450 - acc: 0.9714\n",
      "Epoch 1404/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1449 - acc: 0.9714\n",
      "Epoch 1405/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1448 - acc: 0.9714\n",
      "Epoch 1406/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1446 - acc: 0.9714\n",
      "Epoch 1407/2000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.1445 - acc: 0.9714\n",
      "Epoch 1408/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1444 - acc: 0.9714\n",
      "Epoch 1409/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1443 - acc: 0.9714\n",
      "Epoch 1410/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1442 - acc: 0.9714\n",
      "Epoch 1411/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1441 - acc: 0.9714\n",
      "Epoch 1412/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1440 - acc: 0.9714\n",
      "Epoch 1413/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1438 - acc: 0.9714\n",
      "Epoch 1414/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1437 - acc: 0.9714\n",
      "Epoch 1415/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1436 - acc: 0.9714\n",
      "Epoch 1416/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1435 - acc: 0.9714\n",
      "Epoch 1417/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1434 - acc: 0.9714\n",
      "Epoch 1418/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1433 - acc: 0.9714\n",
      "Epoch 1419/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1432 - acc: 0.9714\n",
      "Epoch 1420/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1431 - acc: 0.9714\n",
      "Epoch 1421/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1430 - acc: 0.9714\n",
      "Epoch 1422/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1429 - acc: 0.9714\n",
      "Epoch 1423/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1427 - acc: 0.9714\n",
      "Epoch 1424/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1426 - acc: 0.9714\n",
      "Epoch 1425/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1425 - acc: 0.9714\n",
      "Epoch 1426/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1424 - acc: 0.9714\n",
      "Epoch 1427/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1423 - acc: 0.9714\n",
      "Epoch 1428/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1422 - acc: 0.9714\n",
      "Epoch 1429/2000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.1421 - acc: 0.9714\n",
      "Epoch 1430/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1420 - acc: 0.9714\n",
      "Epoch 1431/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1419 - acc: 0.9714\n",
      "Epoch 1432/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1418 - acc: 0.9714\n",
      "Epoch 1433/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1417 - acc: 0.9714\n",
      "Epoch 1434/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.1416 - acc: 0.9714\n",
      "Epoch 1435/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1414 - acc: 0.9714\n",
      "Epoch 1436/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1413 - acc: 0.9714\n",
      "Epoch 1437/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1412 - acc: 0.9714\n",
      "Epoch 1438/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1411 - acc: 0.9714\n",
      "Epoch 1439/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1410 - acc: 0.9714\n",
      "Epoch 1440/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1409 - acc: 0.9714\n",
      "Epoch 1441/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1408 - acc: 0.9714\n",
      "Epoch 1442/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1407 - acc: 0.9714\n",
      "Epoch 1443/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1406 - acc: 0.9714\n",
      "Epoch 1444/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1405 - acc: 0.9714\n",
      "Epoch 1445/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1404 - acc: 0.9714\n",
      "Epoch 1446/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1403 - acc: 0.9714\n",
      "Epoch 1447/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1402 - acc: 0.9714\n",
      "Epoch 1448/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1401 - acc: 0.9714\n",
      "Epoch 1449/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1400 - acc: 0.9714\n",
      "Epoch 1450/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1399 - acc: 0.9714\n",
      "Epoch 1451/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1398 - acc: 0.9714\n",
      "Epoch 1452/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1397 - acc: 0.9714\n",
      "Epoch 1453/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1396 - acc: 0.9714\n",
      "Epoch 1454/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1395 - acc: 0.9714\n",
      "Epoch 1455/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1394 - acc: 0.9714\n",
      "Epoch 1456/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1393 - acc: 0.9714\n",
      "Epoch 1457/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1392 - acc: 0.9714\n",
      "Epoch 1458/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1391 - acc: 0.9714\n",
      "Epoch 1459/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1390 - acc: 0.9714\n",
      "Epoch 1460/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1389 - acc: 0.9714\n",
      "Epoch 1461/2000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.1388 - acc: 0.9714\n",
      "Epoch 1462/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1387 - acc: 0.9714\n",
      "Epoch 1463/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1386 - acc: 0.9714\n",
      "Epoch 1464/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1385 - acc: 0.9714\n",
      "Epoch 1465/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1384 - acc: 0.9714\n",
      "Epoch 1466/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1383 - acc: 0.9714\n",
      "Epoch 1467/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1382 - acc: 0.9714\n",
      "Epoch 1468/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1381 - acc: 0.9714\n",
      "Epoch 1469/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 62us/step - loss: 0.1380 - acc: 0.9714\n",
      "Epoch 1470/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1379 - acc: 0.9714\n",
      "Epoch 1471/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1378 - acc: 0.9714\n",
      "Epoch 1472/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1377 - acc: 0.9714\n",
      "Epoch 1473/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1376 - acc: 0.9714\n",
      "Epoch 1474/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1375 - acc: 0.9714\n",
      "Epoch 1475/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1374 - acc: 0.9714\n",
      "Epoch 1476/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1373 - acc: 0.9714\n",
      "Epoch 1477/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1372 - acc: 0.9714\n",
      "Epoch 1478/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1371 - acc: 0.9714\n",
      "Epoch 1479/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1370 - acc: 0.9714\n",
      "Epoch 1480/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1369 - acc: 0.9714\n",
      "Epoch 1481/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1368 - acc: 0.9714\n",
      "Epoch 1482/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1367 - acc: 0.9714\n",
      "Epoch 1483/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1366 - acc: 0.9714\n",
      "Epoch 1484/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1365 - acc: 0.9714\n",
      "Epoch 1485/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1364 - acc: 0.9714\n",
      "Epoch 1486/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1363 - acc: 0.9714\n",
      "Epoch 1487/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1362 - acc: 0.9714\n",
      "Epoch 1488/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1361 - acc: 0.9714\n",
      "Epoch 1489/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1360 - acc: 0.9714\n",
      "Epoch 1490/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1359 - acc: 0.9714\n",
      "Epoch 1491/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1358 - acc: 0.9714\n",
      "Epoch 1492/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1357 - acc: 0.9714\n",
      "Epoch 1493/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1356 - acc: 0.9714\n",
      "Epoch 1494/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1356 - acc: 0.9714\n",
      "Epoch 1495/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1355 - acc: 0.9714\n",
      "Epoch 1496/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1354 - acc: 0.9714\n",
      "Epoch 1497/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1353 - acc: 0.9714\n",
      "Epoch 1498/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1352 - acc: 0.9714\n",
      "Epoch 1499/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1351 - acc: 0.9714\n",
      "Epoch 1500/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1350 - acc: 0.9714\n",
      "Epoch 1501/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1349 - acc: 0.9714\n",
      "Epoch 1502/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1348 - acc: 0.9714\n",
      "Epoch 1503/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1347 - acc: 0.9714\n",
      "Epoch 1504/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1346 - acc: 0.9714\n",
      "Epoch 1505/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1345 - acc: 0.9714\n",
      "Epoch 1506/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1344 - acc: 0.9714\n",
      "Epoch 1507/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1343 - acc: 0.9714\n",
      "Epoch 1508/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1343 - acc: 0.9714\n",
      "Epoch 1509/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1342 - acc: 0.9714\n",
      "Epoch 1510/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1341 - acc: 0.9714\n",
      "Epoch 1511/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1340 - acc: 0.9714\n",
      "Epoch 1512/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1339 - acc: 0.9714\n",
      "Epoch 1513/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1338 - acc: 0.9714\n",
      "Epoch 1514/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1337 - acc: 0.9714\n",
      "Epoch 1515/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1336 - acc: 0.9714\n",
      "Epoch 1516/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1335 - acc: 0.9714\n",
      "Epoch 1517/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1334 - acc: 0.9714\n",
      "Epoch 1518/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1334 - acc: 0.9714\n",
      "Epoch 1519/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1333 - acc: 0.9714\n",
      "Epoch 1520/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1332 - acc: 0.9714\n",
      "Epoch 1521/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1331 - acc: 0.9714\n",
      "Epoch 1522/2000\n",
      "105/105 [==============================] - 0s 81us/step - loss: 0.1330 - acc: 0.9714\n",
      "Epoch 1523/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1329 - acc: 0.9714\n",
      "Epoch 1524/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1328 - acc: 0.9714\n",
      "Epoch 1525/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1327 - acc: 0.9714\n",
      "Epoch 1526/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1326 - acc: 0.9714\n",
      "Epoch 1527/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1326 - acc: 0.9714\n",
      "Epoch 1528/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1325 - acc: 0.9714\n",
      "Epoch 1529/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1324 - acc: 0.9714\n",
      "Epoch 1530/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1323 - acc: 0.9714\n",
      "Epoch 1531/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1322 - acc: 0.9714\n",
      "Epoch 1532/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1321 - acc: 0.9714\n",
      "Epoch 1533/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1320 - acc: 0.9714\n",
      "Epoch 1534/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1320 - acc: 0.9714\n",
      "Epoch 1535/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1319 - acc: 0.9714\n",
      "Epoch 1536/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1318 - acc: 0.9714\n",
      "Epoch 1537/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1317 - acc: 0.9714\n",
      "Epoch 1538/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1316 - acc: 0.9714\n",
      "Epoch 1539/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1315 - acc: 0.9714\n",
      "Epoch 1540/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1314 - acc: 0.9714\n",
      "Epoch 1541/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1314 - acc: 0.9714\n",
      "Epoch 1542/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1313 - acc: 0.9714\n",
      "Epoch 1543/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1312 - acc: 0.9714\n",
      "Epoch 1544/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1311 - acc: 0.9714\n",
      "Epoch 1545/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1310 - acc: 0.9714\n",
      "Epoch 1546/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1309 - acc: 0.9714\n",
      "Epoch 1547/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1308 - acc: 0.9714\n",
      "Epoch 1548/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1308 - acc: 0.9714\n",
      "Epoch 1549/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1307 - acc: 0.9714\n",
      "Epoch 1550/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1306 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1551/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1305 - acc: 0.9714\n",
      "Epoch 1552/2000\n",
      "105/105 [==============================] - 0s 101us/step - loss: 0.1304 - acc: 0.9714\n",
      "Epoch 1553/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1303 - acc: 0.9714\n",
      "Epoch 1554/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1303 - acc: 0.9714\n",
      "Epoch 1555/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1302 - acc: 0.9714\n",
      "Epoch 1556/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1301 - acc: 0.9714\n",
      "Epoch 1557/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1300 - acc: 0.9714\n",
      "Epoch 1558/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1299 - acc: 0.9714\n",
      "Epoch 1559/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1299 - acc: 0.9714\n",
      "Epoch 1560/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1298 - acc: 0.9714\n",
      "Epoch 1561/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1297 - acc: 0.9714\n",
      "Epoch 1562/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1296 - acc: 0.9714\n",
      "Epoch 1563/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1295 - acc: 0.9714\n",
      "Epoch 1564/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1294 - acc: 0.9714\n",
      "Epoch 1565/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1294 - acc: 0.9714\n",
      "Epoch 1566/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1293 - acc: 0.9714\n",
      "Epoch 1567/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1292 - acc: 0.9714\n",
      "Epoch 1568/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1291 - acc: 0.9714\n",
      "Epoch 1569/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1290 - acc: 0.9714\n",
      "Epoch 1570/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1290 - acc: 0.9714\n",
      "Epoch 1571/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1289 - acc: 0.9714\n",
      "Epoch 1572/2000\n",
      "105/105 [==============================] - 0s 36us/step - loss: 0.1288 - acc: 0.9714\n",
      "Epoch 1573/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1287 - acc: 0.9714\n",
      "Epoch 1574/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1286 - acc: 0.9714\n",
      "Epoch 1575/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1286 - acc: 0.9714\n",
      "Epoch 1576/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1285 - acc: 0.9714\n",
      "Epoch 1577/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1284 - acc: 0.9714\n",
      "Epoch 1578/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1283 - acc: 0.9714\n",
      "Epoch 1579/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1283 - acc: 0.9714\n",
      "Epoch 1580/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1282 - acc: 0.9714\n",
      "Epoch 1581/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1281 - acc: 0.9714\n",
      "Epoch 1582/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1280 - acc: 0.9714\n",
      "Epoch 1583/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1279 - acc: 0.9714\n",
      "Epoch 1584/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1279 - acc: 0.9714\n",
      "Epoch 1585/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1278 - acc: 0.9714\n",
      "Epoch 1586/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1277 - acc: 0.9714\n",
      "Epoch 1587/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1276 - acc: 0.9714\n",
      "Epoch 1588/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1276 - acc: 0.9714\n",
      "Epoch 1589/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1275 - acc: 0.9714\n",
      "Epoch 1590/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1274 - acc: 0.9714\n",
      "Epoch 1591/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1273 - acc: 0.9714\n",
      "Epoch 1592/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1272 - acc: 0.9714\n",
      "Epoch 1593/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1272 - acc: 0.9714\n",
      "Epoch 1594/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1271 - acc: 0.9714\n",
      "Epoch 1595/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1270 - acc: 0.9714\n",
      "Epoch 1596/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1269 - acc: 0.9714\n",
      "Epoch 1597/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1269 - acc: 0.9714\n",
      "Epoch 1598/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1268 - acc: 0.9714\n",
      "Epoch 1599/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1267 - acc: 0.9714\n",
      "Epoch 1600/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.1266 - acc: 0.9714\n",
      "Epoch 1601/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1266 - acc: 0.9714\n",
      "Epoch 1602/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1265 - acc: 0.9714\n",
      "Epoch 1603/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1264 - acc: 0.9714\n",
      "Epoch 1604/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1263 - acc: 0.9714\n",
      "Epoch 1605/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1263 - acc: 0.9714\n",
      "Epoch 1606/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1262 - acc: 0.9714\n",
      "Epoch 1607/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1261 - acc: 0.9714\n",
      "Epoch 1608/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1260 - acc: 0.9714\n",
      "Epoch 1609/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1260 - acc: 0.9714\n",
      "Epoch 1610/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1259 - acc: 0.9714\n",
      "Epoch 1611/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1258 - acc: 0.9714\n",
      "Epoch 1612/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1257 - acc: 0.9714\n",
      "Epoch 1613/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1257 - acc: 0.9714\n",
      "Epoch 1614/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1256 - acc: 0.9714\n",
      "Epoch 1615/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1255 - acc: 0.9714\n",
      "Epoch 1616/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1255 - acc: 0.9714\n",
      "Epoch 1617/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1254 - acc: 0.9714\n",
      "Epoch 1618/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1253 - acc: 0.9714\n",
      "Epoch 1619/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1252 - acc: 0.9714\n",
      "Epoch 1620/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1252 - acc: 0.9714\n",
      "Epoch 1621/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1251 - acc: 0.9714\n",
      "Epoch 1622/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1250 - acc: 0.9714\n",
      "Epoch 1623/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1249 - acc: 0.9714\n",
      "Epoch 1624/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1249 - acc: 0.9714\n",
      "Epoch 1625/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1248 - acc: 0.9714\n",
      "Epoch 1626/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1247 - acc: 0.9714\n",
      "Epoch 1627/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1247 - acc: 0.9714\n",
      "Epoch 1628/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1246 - acc: 0.9714\n",
      "Epoch 1629/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1245 - acc: 0.9714\n",
      "Epoch 1630/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1244 - acc: 0.9714\n",
      "Epoch 1631/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1244 - acc: 0.9714\n",
      "Epoch 1632/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 58us/step - loss: 0.1243 - acc: 0.9714\n",
      "Epoch 1633/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1242 - acc: 0.9714\n",
      "Epoch 1634/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1242 - acc: 0.9714\n",
      "Epoch 1635/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1241 - acc: 0.9714\n",
      "Epoch 1636/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1240 - acc: 0.9714\n",
      "Epoch 1637/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1239 - acc: 0.9714\n",
      "Epoch 1638/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1239 - acc: 0.9714\n",
      "Epoch 1639/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1238 - acc: 0.9714\n",
      "Epoch 1640/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1237 - acc: 0.9714\n",
      "Epoch 1641/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1237 - acc: 0.9714\n",
      "Epoch 1642/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1236 - acc: 0.9714\n",
      "Epoch 1643/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1235 - acc: 0.9714\n",
      "Epoch 1644/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1235 - acc: 0.9714\n",
      "Epoch 1645/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1234 - acc: 0.9714\n",
      "Epoch 1646/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1233 - acc: 0.9714\n",
      "Epoch 1647/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1233 - acc: 0.9714\n",
      "Epoch 1648/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1232 - acc: 0.9714\n",
      "Epoch 1649/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1231 - acc: 0.9714\n",
      "Epoch 1650/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1231 - acc: 0.9714\n",
      "Epoch 1651/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1230 - acc: 0.9714\n",
      "Epoch 1652/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1229 - acc: 0.9714\n",
      "Epoch 1653/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1228 - acc: 0.9714\n",
      "Epoch 1654/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1228 - acc: 0.9714\n",
      "Epoch 1655/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1227 - acc: 0.9714\n",
      "Epoch 1656/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.1226 - acc: 0.9714\n",
      "Epoch 1657/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1226 - acc: 0.9714\n",
      "Epoch 1658/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1225 - acc: 0.9714\n",
      "Epoch 1659/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1224 - acc: 0.9714\n",
      "Epoch 1660/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1224 - acc: 0.9714\n",
      "Epoch 1661/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1223 - acc: 0.9714\n",
      "Epoch 1662/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1222 - acc: 0.9714\n",
      "Epoch 1663/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1222 - acc: 0.9714\n",
      "Epoch 1664/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1221 - acc: 0.9714\n",
      "Epoch 1665/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1220 - acc: 0.9714\n",
      "Epoch 1666/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1220 - acc: 0.9714\n",
      "Epoch 1667/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1219 - acc: 0.9714\n",
      "Epoch 1668/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1218 - acc: 0.9714\n",
      "Epoch 1669/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1218 - acc: 0.9714\n",
      "Epoch 1670/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1217 - acc: 0.9714\n",
      "Epoch 1671/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1216 - acc: 0.9714\n",
      "Epoch 1672/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1216 - acc: 0.9714\n",
      "Epoch 1673/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1215 - acc: 0.9714\n",
      "Epoch 1674/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1214 - acc: 0.9714\n",
      "Epoch 1675/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1214 - acc: 0.9714\n",
      "Epoch 1676/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1213 - acc: 0.9714\n",
      "Epoch 1677/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1213 - acc: 0.9714\n",
      "Epoch 1678/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1212 - acc: 0.9714\n",
      "Epoch 1679/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1211 - acc: 0.9714\n",
      "Epoch 1680/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1211 - acc: 0.9714\n",
      "Epoch 1681/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1210 - acc: 0.9714\n",
      "Epoch 1682/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1209 - acc: 0.9714\n",
      "Epoch 1683/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1209 - acc: 0.9714\n",
      "Epoch 1684/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1208 - acc: 0.9714\n",
      "Epoch 1685/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1207 - acc: 0.9714\n",
      "Epoch 1686/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1207 - acc: 0.9714\n",
      "Epoch 1687/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1206 - acc: 0.9714\n",
      "Epoch 1688/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1205 - acc: 0.9714\n",
      "Epoch 1689/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1205 - acc: 0.9714\n",
      "Epoch 1690/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1204 - acc: 0.9714\n",
      "Epoch 1691/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1204 - acc: 0.9714\n",
      "Epoch 1692/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1203 - acc: 0.9714\n",
      "Epoch 1693/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1202 - acc: 0.9714\n",
      "Epoch 1694/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1202 - acc: 0.9714\n",
      "Epoch 1695/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1201 - acc: 0.9714\n",
      "Epoch 1696/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1200 - acc: 0.9714\n",
      "Epoch 1697/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1200 - acc: 0.9714\n",
      "Epoch 1698/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1199 - acc: 0.9714\n",
      "Epoch 1699/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1199 - acc: 0.9714\n",
      "Epoch 1700/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1198 - acc: 0.9714\n",
      "Epoch 1701/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1197 - acc: 0.9714\n",
      "Epoch 1702/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1197 - acc: 0.9714\n",
      "Epoch 1703/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1196 - acc: 0.9714\n",
      "Epoch 1704/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1195 - acc: 0.9714\n",
      "Epoch 1705/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1195 - acc: 0.9714\n",
      "Epoch 1706/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1194 - acc: 0.9714\n",
      "Epoch 1707/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1194 - acc: 0.9714\n",
      "Epoch 1708/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1193 - acc: 0.9714\n",
      "Epoch 1709/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1192 - acc: 0.9714\n",
      "Epoch 1710/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1192 - acc: 0.9714\n",
      "Epoch 1711/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1191 - acc: 0.9714\n",
      "Epoch 1712/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1191 - acc: 0.9714\n",
      "Epoch 1713/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1190 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1714/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1189 - acc: 0.9714\n",
      "Epoch 1715/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1189 - acc: 0.9714\n",
      "Epoch 1716/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1188 - acc: 0.9714\n",
      "Epoch 1717/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1188 - acc: 0.9714\n",
      "Epoch 1718/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1187 - acc: 0.9714\n",
      "Epoch 1719/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1186 - acc: 0.9714\n",
      "Epoch 1720/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1186 - acc: 0.9714\n",
      "Epoch 1721/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1185 - acc: 0.9714\n",
      "Epoch 1722/2000\n",
      "105/105 [==============================] - 0s 74us/step - loss: 0.1185 - acc: 0.9714\n",
      "Epoch 1723/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1184 - acc: 0.9714\n",
      "Epoch 1724/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1183 - acc: 0.9714\n",
      "Epoch 1725/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1183 - acc: 0.9714\n",
      "Epoch 1726/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1182 - acc: 0.9714\n",
      "Epoch 1727/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1182 - acc: 0.9714\n",
      "Epoch 1728/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1181 - acc: 0.9714\n",
      "Epoch 1729/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1180 - acc: 0.9714\n",
      "Epoch 1730/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1180 - acc: 0.9714\n",
      "Epoch 1731/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1179 - acc: 0.9714\n",
      "Epoch 1732/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1179 - acc: 0.9714\n",
      "Epoch 1733/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1178 - acc: 0.9714\n",
      "Epoch 1734/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1177 - acc: 0.9714\n",
      "Epoch 1735/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1177 - acc: 0.9714\n",
      "Epoch 1736/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1176 - acc: 0.9714\n",
      "Epoch 1737/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1176 - acc: 0.9714\n",
      "Epoch 1738/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1175 - acc: 0.9714\n",
      "Epoch 1739/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1175 - acc: 0.9714\n",
      "Epoch 1740/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1174 - acc: 0.9714\n",
      "Epoch 1741/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1173 - acc: 0.9714\n",
      "Epoch 1742/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1173 - acc: 0.9714\n",
      "Epoch 1743/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1172 - acc: 0.9714\n",
      "Epoch 1744/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1172 - acc: 0.9714\n",
      "Epoch 1745/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1171 - acc: 0.9714\n",
      "Epoch 1746/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1171 - acc: 0.9714\n",
      "Epoch 1747/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1170 - acc: 0.9714\n",
      "Epoch 1748/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1169 - acc: 0.9714\n",
      "Epoch 1749/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1169 - acc: 0.9714\n",
      "Epoch 1750/2000\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1168 - acc: 0.9714\n",
      "Epoch 1751/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1168 - acc: 0.9714\n",
      "Epoch 1752/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1167 - acc: 0.9714\n",
      "Epoch 1753/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1167 - acc: 0.9714\n",
      "Epoch 1754/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1166 - acc: 0.9714\n",
      "Epoch 1755/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1165 - acc: 0.9714\n",
      "Epoch 1756/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1165 - acc: 0.9714\n",
      "Epoch 1757/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1164 - acc: 0.9714\n",
      "Epoch 1758/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1164 - acc: 0.9714\n",
      "Epoch 1759/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1163 - acc: 0.9714\n",
      "Epoch 1760/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1163 - acc: 0.9714\n",
      "Epoch 1761/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1162 - acc: 0.9714\n",
      "Epoch 1762/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1162 - acc: 0.9714\n",
      "Epoch 1763/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1161 - acc: 0.9714\n",
      "Epoch 1764/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1160 - acc: 0.9714\n",
      "Epoch 1765/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1160 - acc: 0.9714\n",
      "Epoch 1766/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1159 - acc: 0.9714\n",
      "Epoch 1767/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1159 - acc: 0.9714\n",
      "Epoch 1768/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1158 - acc: 0.9714\n",
      "Epoch 1769/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1158 - acc: 0.9714\n",
      "Epoch 1770/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1157 - acc: 0.9714\n",
      "Epoch 1771/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1157 - acc: 0.9714\n",
      "Epoch 1772/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1156 - acc: 0.9714\n",
      "Epoch 1773/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1155 - acc: 0.9714\n",
      "Epoch 1774/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1155 - acc: 0.9714\n",
      "Epoch 1775/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1154 - acc: 0.9714\n",
      "Epoch 1776/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1154 - acc: 0.9714\n",
      "Epoch 1777/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1153 - acc: 0.9714\n",
      "Epoch 1778/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1153 - acc: 0.9714\n",
      "Epoch 1779/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1152 - acc: 0.9714\n",
      "Epoch 1780/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1152 - acc: 0.9714\n",
      "Epoch 1781/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1151 - acc: 0.9714\n",
      "Epoch 1782/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1151 - acc: 0.9714\n",
      "Epoch 1783/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1150 - acc: 0.9714\n",
      "Epoch 1784/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1150 - acc: 0.9714\n",
      "Epoch 1785/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1149 - acc: 0.9714\n",
      "Epoch 1786/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1149 - acc: 0.9714\n",
      "Epoch 1787/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1148 - acc: 0.9714\n",
      "Epoch 1788/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1147 - acc: 0.9714\n",
      "Epoch 1789/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1147 - acc: 0.9714\n",
      "Epoch 1790/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1146 - acc: 0.9714\n",
      "Epoch 1791/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1146 - acc: 0.9714\n",
      "Epoch 1792/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1145 - acc: 0.9714\n",
      "Epoch 1793/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1145 - acc: 0.9714\n",
      "Epoch 1794/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1144 - acc: 0.9714\n",
      "Epoch 1795/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 49us/step - loss: 0.1144 - acc: 0.9714\n",
      "Epoch 1796/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1143 - acc: 0.9714\n",
      "Epoch 1797/2000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.1143 - acc: 0.9714\n",
      "Epoch 1798/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1142 - acc: 0.9714\n",
      "Epoch 1799/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1142 - acc: 0.9714\n",
      "Epoch 1800/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1141 - acc: 0.9714\n",
      "Epoch 1801/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1141 - acc: 0.9714\n",
      "Epoch 1802/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1140 - acc: 0.9714\n",
      "Epoch 1803/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1140 - acc: 0.9714\n",
      "Epoch 1804/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1139 - acc: 0.9714\n",
      "Epoch 1805/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1139 - acc: 0.9714\n",
      "Epoch 1806/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1138 - acc: 0.9714\n",
      "Epoch 1807/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1138 - acc: 0.9714\n",
      "Epoch 1808/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1137 - acc: 0.9714\n",
      "Epoch 1809/2000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.1137 - acc: 0.9714\n",
      "Epoch 1810/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1136 - acc: 0.9714\n",
      "Epoch 1811/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1136 - acc: 0.9714\n",
      "Epoch 1812/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1135 - acc: 0.9714\n",
      "Epoch 1813/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1135 - acc: 0.9714\n",
      "Epoch 1814/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1134 - acc: 0.9714\n",
      "Epoch 1815/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1133 - acc: 0.9714\n",
      "Epoch 1816/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1133 - acc: 0.9714\n",
      "Epoch 1817/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1132 - acc: 0.9714\n",
      "Epoch 1818/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1132 - acc: 0.9714\n",
      "Epoch 1819/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1131 - acc: 0.9714\n",
      "Epoch 1820/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1131 - acc: 0.9714\n",
      "Epoch 1821/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1130 - acc: 0.9714\n",
      "Epoch 1822/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1130 - acc: 0.9714\n",
      "Epoch 1823/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1129 - acc: 0.9714\n",
      "Epoch 1824/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1129 - acc: 0.9714\n",
      "Epoch 1825/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1128 - acc: 0.9714\n",
      "Epoch 1826/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1128 - acc: 0.9714\n",
      "Epoch 1827/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1127 - acc: 0.9714\n",
      "Epoch 1828/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1127 - acc: 0.9714\n",
      "Epoch 1829/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1127 - acc: 0.9714\n",
      "Epoch 1830/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1126 - acc: 0.9714\n",
      "Epoch 1831/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1126 - acc: 0.9714\n",
      "Epoch 1832/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1125 - acc: 0.9714\n",
      "Epoch 1833/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1125 - acc: 0.9714\n",
      "Epoch 1834/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1124 - acc: 0.9714\n",
      "Epoch 1835/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1124 - acc: 0.9714\n",
      "Epoch 1836/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1123 - acc: 0.9714\n",
      "Epoch 1837/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1123 - acc: 0.9714\n",
      "Epoch 1838/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1122 - acc: 0.9714\n",
      "Epoch 1839/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1122 - acc: 0.9714\n",
      "Epoch 1840/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1121 - acc: 0.9714\n",
      "Epoch 1841/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1121 - acc: 0.9714\n",
      "Epoch 1842/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1120 - acc: 0.9714\n",
      "Epoch 1843/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1120 - acc: 0.9714\n",
      "Epoch 1844/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1119 - acc: 0.9714\n",
      "Epoch 1845/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1119 - acc: 0.9714\n",
      "Epoch 1846/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1118 - acc: 0.9714\n",
      "Epoch 1847/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1118 - acc: 0.9714\n",
      "Epoch 1848/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1117 - acc: 0.9714\n",
      "Epoch 1849/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1117 - acc: 0.9714\n",
      "Epoch 1850/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1116 - acc: 0.9714\n",
      "Epoch 1851/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1116 - acc: 0.9714\n",
      "Epoch 1852/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1115 - acc: 0.9714\n",
      "Epoch 1853/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1115 - acc: 0.9714\n",
      "Epoch 1854/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1114 - acc: 0.9714\n",
      "Epoch 1855/2000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.1114 - acc: 0.9714\n",
      "Epoch 1856/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1114 - acc: 0.9714\n",
      "Epoch 1857/2000\n",
      "105/105 [==============================] - 0s 89us/step - loss: 0.1113 - acc: 0.9714\n",
      "Epoch 1858/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1113 - acc: 0.9714\n",
      "Epoch 1859/2000\n",
      "105/105 [==============================] - 0s 82us/step - loss: 0.1112 - acc: 0.9714\n",
      "Epoch 1860/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1112 - acc: 0.9714\n",
      "Epoch 1861/2000\n",
      "105/105 [==============================] - 0s 80us/step - loss: 0.1111 - acc: 0.9714\n",
      "Epoch 1862/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1111 - acc: 0.9714\n",
      "Epoch 1863/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1110 - acc: 0.9714\n",
      "Epoch 1864/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1110 - acc: 0.9714\n",
      "Epoch 1865/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1109 - acc: 0.9714\n",
      "Epoch 1866/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1109 - acc: 0.9714\n",
      "Epoch 1867/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1108 - acc: 0.9714\n",
      "Epoch 1868/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1108 - acc: 0.9714\n",
      "Epoch 1869/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1107 - acc: 0.9714\n",
      "Epoch 1870/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1107 - acc: 0.9714\n",
      "Epoch 1871/2000\n",
      "105/105 [==============================] - 0s 78us/step - loss: 0.1107 - acc: 0.9714\n",
      "Epoch 1872/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1106 - acc: 0.9714\n",
      "Epoch 1873/2000\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.1106 - acc: 0.9714\n",
      "Epoch 1874/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1105 - acc: 0.9714\n",
      "Epoch 1875/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1105 - acc: 0.9714\n",
      "Epoch 1876/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1104 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1877/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1104 - acc: 0.9714\n",
      "Epoch 1878/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1103 - acc: 0.9714\n",
      "Epoch 1879/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1103 - acc: 0.9714\n",
      "Epoch 1880/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1102 - acc: 0.9714\n",
      "Epoch 1881/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1102 - acc: 0.9714\n",
      "Epoch 1882/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1102 - acc: 0.9714\n",
      "Epoch 1883/2000\n",
      "105/105 [==============================] - 0s 94us/step - loss: 0.1101 - acc: 0.9714\n",
      "Epoch 1884/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1101 - acc: 0.9714\n",
      "Epoch 1885/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1100 - acc: 0.9714\n",
      "Epoch 1886/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1100 - acc: 0.9714\n",
      "Epoch 1887/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1099 - acc: 0.9714\n",
      "Epoch 1888/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1099 - acc: 0.9714\n",
      "Epoch 1889/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1098 - acc: 0.9714\n",
      "Epoch 1890/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1098 - acc: 0.9714\n",
      "Epoch 1891/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1098 - acc: 0.9714\n",
      "Epoch 1892/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1097 - acc: 0.9714\n",
      "Epoch 1893/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1097 - acc: 0.9714\n",
      "Epoch 1894/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1096 - acc: 0.9714\n",
      "Epoch 1895/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1096 - acc: 0.9714\n",
      "Epoch 1896/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1095 - acc: 0.9714\n",
      "Epoch 1897/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1095 - acc: 0.9714\n",
      "Epoch 1898/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1094 - acc: 0.9714\n",
      "Epoch 1899/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1094 - acc: 0.9714\n",
      "Epoch 1900/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1094 - acc: 0.9714\n",
      "Epoch 1901/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1093 - acc: 0.9714\n",
      "Epoch 1902/2000\n",
      "105/105 [==============================] - 0s 43us/step - loss: 0.1093 - acc: 0.9714\n",
      "Epoch 1903/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1092 - acc: 0.9714\n",
      "Epoch 1904/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1092 - acc: 0.9714\n",
      "Epoch 1905/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1091 - acc: 0.9714\n",
      "Epoch 1906/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1091 - acc: 0.9714\n",
      "Epoch 1907/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1091 - acc: 0.9714\n",
      "Epoch 1908/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.1090 - acc: 0.9714\n",
      "Epoch 1909/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1090 - acc: 0.9714\n",
      "Epoch 1910/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1089 - acc: 0.9714\n",
      "Epoch 1911/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1089 - acc: 0.9714\n",
      "Epoch 1912/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1088 - acc: 0.9714\n",
      "Epoch 1913/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1088 - acc: 0.9714\n",
      "Epoch 1914/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1088 - acc: 0.9714\n",
      "Epoch 1915/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1087 - acc: 0.9714\n",
      "Epoch 1916/2000\n",
      "105/105 [==============================] - 0s 41us/step - loss: 0.1087 - acc: 0.9714\n",
      "Epoch 1917/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1086 - acc: 0.9714\n",
      "Epoch 1918/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1086 - acc: 0.9714\n",
      "Epoch 1919/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1085 - acc: 0.9714\n",
      "Epoch 1920/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1085 - acc: 0.9714\n",
      "Epoch 1921/2000\n",
      "105/105 [==============================] - 0s 49us/step - loss: 0.1085 - acc: 0.9714\n",
      "Epoch 1922/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1084 - acc: 0.9714\n",
      "Epoch 1923/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1084 - acc: 0.9714\n",
      "Epoch 1924/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1083 - acc: 0.9714\n",
      "Epoch 1925/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1083 - acc: 0.9714\n",
      "Epoch 1926/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1082 - acc: 0.9714\n",
      "Epoch 1927/2000\n",
      "105/105 [==============================] - 0s 40us/step - loss: 0.1082 - acc: 0.9714\n",
      "Epoch 1928/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1082 - acc: 0.9714\n",
      "Epoch 1929/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1081 - acc: 0.9714\n",
      "Epoch 1930/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1081 - acc: 0.9714\n",
      "Epoch 1931/2000\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1080 - acc: 0.9714\n",
      "Epoch 1932/2000\n",
      "105/105 [==============================] - 0s 37us/step - loss: 0.1080 - acc: 0.9714\n",
      "Epoch 1933/2000\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.1080 - acc: 0.9714\n",
      "Epoch 1934/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1079 - acc: 0.9714\n",
      "Epoch 1935/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1079 - acc: 0.9714\n",
      "Epoch 1936/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1078 - acc: 0.9714\n",
      "Epoch 1937/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1078 - acc: 0.9714\n",
      "Epoch 1938/2000\n",
      "105/105 [==============================] - 0s 53us/step - loss: 0.1077 - acc: 0.9714\n",
      "Epoch 1939/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1077 - acc: 0.9714\n",
      "Epoch 1940/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1077 - acc: 0.9714\n",
      "Epoch 1941/2000\n",
      "105/105 [==============================] - 0s 79us/step - loss: 0.1076 - acc: 0.9714\n",
      "Epoch 1942/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1076 - acc: 0.9714\n",
      "Epoch 1943/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1075 - acc: 0.9714\n",
      "Epoch 1944/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1075 - acc: 0.9714\n",
      "Epoch 1945/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1075 - acc: 0.9714\n",
      "Epoch 1946/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1074 - acc: 0.9714\n",
      "Epoch 1947/2000\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1074 - acc: 0.9714\n",
      "Epoch 1948/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1073 - acc: 0.9714\n",
      "Epoch 1949/2000\n",
      "105/105 [==============================] - 0s 62us/step - loss: 0.1073 - acc: 0.9714\n",
      "Epoch 1950/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1073 - acc: 0.9714\n",
      "Epoch 1951/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1072 - acc: 0.9714\n",
      "Epoch 1952/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1072 - acc: 0.9714\n",
      "Epoch 1953/2000\n",
      "105/105 [==============================] - 0s 46us/step - loss: 0.1071 - acc: 0.9714\n",
      "Epoch 1954/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1071 - acc: 0.9714\n",
      "Epoch 1955/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1071 - acc: 0.9714\n",
      "Epoch 1956/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1070 - acc: 0.9714\n",
      "Epoch 1957/2000\n",
      "105/105 [==============================] - 0s 68us/step - loss: 0.1070 - acc: 0.9714\n",
      "Epoch 1958/2000\n",
      "105/105 [==============================] - 0s 39us/step - loss: 0.1069 - acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1959/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1069 - acc: 0.9714\n",
      "Epoch 1960/2000\n",
      "105/105 [==============================] - 0s 58us/step - loss: 0.1069 - acc: 0.9714\n",
      "Epoch 1961/2000\n",
      "105/105 [==============================] - 0s 75us/step - loss: 0.1068 - acc: 0.9714\n",
      "Epoch 1962/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1068 - acc: 0.9714\n",
      "Epoch 1963/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1067 - acc: 0.9714\n",
      "Epoch 1964/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1067 - acc: 0.9714\n",
      "Epoch 1965/2000\n",
      "105/105 [==============================] - 0s 73us/step - loss: 0.1067 - acc: 0.9714\n",
      "Epoch 1966/2000\n",
      "105/105 [==============================] - 0s 119us/step - loss: 0.1066 - acc: 0.9714\n",
      "Epoch 1967/2000\n",
      "105/105 [==============================] - 0s 44us/step - loss: 0.1066 - acc: 0.9714\n",
      "Epoch 1968/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1065 - acc: 0.9714\n",
      "Epoch 1969/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1065 - acc: 0.9714\n",
      "Epoch 1970/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1065 - acc: 0.9714\n",
      "Epoch 1971/2000\n",
      "105/105 [==============================] - 0s 64us/step - loss: 0.1064 - acc: 0.9714\n",
      "Epoch 1972/2000\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.1064 - acc: 0.9714\n",
      "Epoch 1973/2000\n",
      "105/105 [==============================] - 0s 69us/step - loss: 0.1063 - acc: 0.9714\n",
      "Epoch 1974/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1063 - acc: 0.9714\n",
      "Epoch 1975/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1063 - acc: 0.9714\n",
      "Epoch 1976/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1062 - acc: 0.9714\n",
      "Epoch 1977/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1062 - acc: 0.9714\n",
      "Epoch 1978/2000\n",
      "105/105 [==============================] - 0s 51us/step - loss: 0.1061 - acc: 0.9714\n",
      "Epoch 1979/2000\n",
      "105/105 [==============================] - 0s 45us/step - loss: 0.1061 - acc: 0.9714\n",
      "Epoch 1980/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1061 - acc: 0.9714\n",
      "Epoch 1981/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1060 - acc: 0.9714\n",
      "Epoch 1982/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1060 - acc: 0.9714\n",
      "Epoch 1983/2000\n",
      "105/105 [==============================] - 0s 42us/step - loss: 0.1060 - acc: 0.9714\n",
      "Epoch 1984/2000\n",
      "105/105 [==============================] - 0s 52us/step - loss: 0.1059 - acc: 0.9714\n",
      "Epoch 1985/2000\n",
      "105/105 [==============================] - 0s 50us/step - loss: 0.1059 - acc: 0.9714\n",
      "Epoch 1986/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1058 - acc: 0.9714\n",
      "Epoch 1987/2000\n",
      "105/105 [==============================] - 0s 59us/step - loss: 0.1058 - acc: 0.9714\n",
      "Epoch 1988/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1058 - acc: 0.9714\n",
      "Epoch 1989/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1057 - acc: 0.9714\n",
      "Epoch 1990/2000\n",
      "105/105 [==============================] - 0s 65us/step - loss: 0.1057 - acc: 0.9714\n",
      "Epoch 1991/2000\n",
      "105/105 [==============================] - 0s 56us/step - loss: 0.1056 - acc: 0.9714\n",
      "Epoch 1992/2000\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1056 - acc: 0.9714\n",
      "Epoch 1993/2000\n",
      "105/105 [==============================] - 0s 71us/step - loss: 0.1056 - acc: 0.9714\n",
      "Epoch 1994/2000\n",
      "105/105 [==============================] - 0s 61us/step - loss: 0.1055 - acc: 0.9714\n",
      "Epoch 1995/2000\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1055 - acc: 0.9714\n",
      "Epoch 1996/2000\n",
      "105/105 [==============================] - 0s 54us/step - loss: 0.1055 - acc: 0.9714\n",
      "Epoch 1997/2000\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.1054 - acc: 0.9714\n",
      "Epoch 1998/2000\n",
      "105/105 [==============================] - 0s 60us/step - loss: 0.1054 - acc: 0.9714\n",
      "Epoch 1999/2000\n",
      "105/105 [==============================] - 0s 70us/step - loss: 0.1053 - acc: 0.9714\n",
      "Epoch 2000/2000\n",
      "105/105 [==============================] - 0s 55us/step - loss: 0.1053 - acc: 0.9714\n",
      "45/45 [==============================] - 1s 20ms/step\n",
      "\\ n loss: 0.06961383389102088\n",
      "\\ n accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# build a sequential model \n",
    "\n",
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 10, activation ='relu', input_shape =( 4,))) # add dropout layer for preventing overfitting \n",
    "#model.add( Dropout( 0.1)) \n",
    "model.add( Dense( units = 8, activation ='relu')) \n",
    "#model.add( Dropout( 0.1)) # output layer can only have the neurons equal to the number of outputs \n",
    "model.add( Dense( units = 3, activation ='softmax')) # print the summary of our model \n",
    "model.summary() \n",
    "\n",
    "# compile the model \n",
    "model.compile( loss ='categorical_crossentropy', optimizer = Adam(), metrics =['accuracy']) \n",
    "\n",
    "# train the model \n",
    "model.fit( x_train1, y_train1, batch_size = batch_size, epochs = n_epochs) \n",
    "\n",
    "# evaluate the model and print the accuracy score \n",
    "\n",
    "scores = model.evaluate( x_test1, y_test1) \n",
    "\n",
    "print('\\ n loss:', scores[ 0]) \n",
    "\n",
    "print('\\ n accuracy:', scores[ 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMqTdhwfTyOf"
   },
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9tI_ZAJTyOg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4-Rfd5iTyOj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z39NQp9dTyOp"
   },
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJL7Lgm-TyOp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_InternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
