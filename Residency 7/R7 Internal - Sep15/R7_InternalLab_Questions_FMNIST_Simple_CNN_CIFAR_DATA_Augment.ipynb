{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ignNNMUsLERl",
    "outputId": "22d7d465-eef0-4e2c-d913-fa49fb4b990f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "%matplotlib inlineciodels import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "g2sf67VoJjvx",
    "outputId": "1dada82f-daf8-47fc-d3d5-98024e79f6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "print ('Train size:', x_train.shape[0])\n",
    "print ('Test size:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zewyDcBlJjv1"
   },
   "outputs": [],
   "source": [
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XycQGBSGJjv5",
    "outputId": "bb2a7eac-bf58-4628-df46-83c562f168a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "x_train = x_train.astype('float32')      # Change the data type to float from integer (0 - 255)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)   # Converting the target into categorical which is stored as numeric\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "WS6JQ0rnM1cX",
    "outputId": "cc3ad5e8-a339-4133-ec09-e018f2c1cdbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "print ('Train size:', x_train.shape[0])\n",
    "print ('Test size:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train /= 255                           # Scale the data between 0 and 1\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN",
    "outputId": "3f3272bb-55a5-4a78-aaf3-390cfc0d2f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x9gC0M7XSw7M",
    "outputId": "6ff41ac5-a54c-4bf8-f6b4-3e392a8c3388"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3RiWXBQPhqx"
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "DORCLgSwJjwV",
    "outputId": "ae9c1d66-9f75-4ae6-eec2-9620275c9215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "# Define model\n",
    "model2 = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "model2.add(Convolution2D(32, 3, 3))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "    # Prediction Layer\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU5uiv03PZUB"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BS7GrG2nPpMT"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Store Training Results\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "id": "PjfDdbsuRLwZ",
    "outputId": "44873c74-9377-4436-aa9b-0bd2604bff4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.3545 - acc: 0.8702 - val_loss: 0.3092 - val_acc: 0.8914\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.2209 - acc: 0.9189 - val_loss: 0.2864 - val_acc: 0.8987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.1544 - acc: 0.9421 - val_loss: 0.2919 - val_acc: 0.9093\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.1072 - acc: 0.9609 - val_loss: 0.3423 - val_acc: 0.9089\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0748 - acc: 0.9730 - val_loss: 0.3711 - val_acc: 0.9144\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0548 - acc: 0.9804 - val_loss: 0.4383 - val_acc: 0.9099\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0421 - acc: 0.9852 - val_loss: 0.4916 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.6297 - val_acc: 0.9059\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0340 - acc: 0.9898 - val_loss: 0.6683 - val_acc: 0.9061\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.6399 - val_acc: 0.9071\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1cd22a76d8>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "L2hAP94vJjwY",
    "outputId": "0e0ef45d-ab58-4d05-a6db-d61c70c17c42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.4609 - acc: 0.8338 - val_loss: 0.3076 - val_acc: 0.8859\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.3280 - acc: 0.8806 - val_loss: 0.2729 - val_acc: 0.9031\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2936 - acc: 0.8949 - val_loss: 0.2522 - val_acc: 0.9085\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.2749 - acc: 0.9008 - val_loss: 0.2605 - val_acc: 0.9092\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2654 - acc: 0.9062 - val_loss: 0.2535 - val_acc: 0.9129\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2538 - acc: 0.9084 - val_loss: 0.2434 - val_acc: 0.9156\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.2491 - acc: 0.9097 - val_loss: 0.2490 - val_acc: 0.9115\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2406 - acc: 0.9131 - val_loss: 0.2471 - val_acc: 0.9129\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.2395 - acc: 0.9160 - val_loss: 0.2523 - val_acc: 0.9142\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2372 - acc: 0.9144 - val_loss: 0.2503 - val_acc: 0.9157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1cc06674e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Model\n",
    "    model3 = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model3.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model3.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model3.add(Convolution2D(32, 3, 3))\n",
    "    model3.add(Activation('relu'))\n",
    "\n",
    "    # Max Pooling\n",
    "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Dropout\n",
    "    model3.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model3.add(Flatten())\n",
    "    model3.add(Dense(128))\n",
    "    model3.add(Activation('relu'))\n",
    "    \n",
    "    # More Dropout\n",
    "    model3.add(Dropout(0.5))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model3.add(Dense(10))\n",
    "    model3.add(Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, verbose=1, mode='auto') \n",
    "    #Stop training when a monitored quantity has stopped improving.\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model\n",
    "    model3.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "DpI1_McYJjwg",
    "outputId": "41612218-9524-41c2-b39b-511ffd37dfb6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/lvIcVi3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "44ZnDdJYJjwn",
    "outputId": "1fa75b8b-ed89-4577-dff0-4d804c8b1137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   9/1875 [..............................] - ETA: 31s - loss: 2.8142 - acc: 0.3958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 30s 16ms/step - loss: 1.1593 - acc: 0.5738 - val_loss: 0.3546 - val_acc: 0.8832\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.8678 - acc: 0.6813 - val_loss: 0.3645 - val_acc: 0.8770\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.7803 - acc: 0.7113 - val_loss: 0.3729 - val_acc: 0.8708\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.7190 - acc: 0.7329 - val_loss: 0.3611 - val_acc: 0.8740\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6865 - acc: 0.7457 - val_loss: 0.3589 - val_acc: 0.8762\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.6659 - acc: 0.7544 - val_loss: 0.3633 - val_acc: 0.8768\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6425 - acc: 0.7650 - val_loss: 0.3615 - val_acc: 0.8792\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6204 - acc: 0.7730 - val_loss: 0.3483 - val_acc: 0.8769\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1cc06a6898>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=32),\n",
    "                    samples_per_epoch=x_train.shape[0],\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1SrtBEPJjwq"
   },
   "outputs": [],
   "source": [
    "Train accuracy = 77.30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBwVWNQC2qZD"
   },
   "outputs": [],
   "source": [
    "Validation accuracy = 87.69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXqmUDW2rM1"
   },
   "source": [
    "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mja6OgQ3L18"
   },
   "source": [
    "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzVTPUM3WZJ"
   },
   "source": [
    "### **Import neessary libraries for data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPM558TX4KMb"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10, mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6hicLwP4SqY"
   },
   "source": [
    "### **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1WzrXd4WNk"
   },
   "outputs": [],
   "source": [
    "(x_traincf, y_traincf), (x_testcf, y_testcf) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9Pht1ggHuiT"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "x_traincf = x_traincf.reshape(x_traincf.shape[0], 32, 32, 3).astype('float32')\n",
    "x_testcf = x_testcf.reshape(x_testcf.shape[0], 32, 32, 3).astype('float32')\n",
    "x_traincf = x_traincf.astype('float32')      # Change the data type to float from integer (0 - 255)\n",
    "x_testcf = x_testcf.astype('float32')\n",
    "\n",
    "y_traincf = keras.utils.to_categorical(y_traincf, num_classes)   # Converting the target into categorical which is stored as numeric\n",
    "y_testcf = keras.utils.to_categorical(y_testcf, num_classes)\n",
    "\n",
    "x_traincf /= 255                           # Scale the data between 0 and 1\n",
    "x_testcf /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "3n28ccU6Hp6s",
    "outputId": "4d4af7b5-a23b-4a1a-8b7c-f484952e8e4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "model4.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "model4.add(Convolution2D(32, 3, 3))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "    # Max Pooling\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Dropout\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128))\n",
    "model4.add(Activation('relu'))\n",
    "    \n",
    "    # More Dropout\n",
    "model4.add(Dropout(0.5))\n",
    "\n",
    "    # Prediction Layer\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "TY4DFg0peJQO",
    "outputId": "f94eda65-dd25-43b1-a893-6639c7e26d79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 1.5661 - acc: 0.4301 - val_loss: 1.2627 - val_acc: 0.5478\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.2949 - acc: 0.5438 - val_loss: 1.1131 - val_acc: 0.6136\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.1898 - acc: 0.5804 - val_loss: 1.0670 - val_acc: 0.6196\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.1314 - acc: 0.6032 - val_loss: 1.0642 - val_acc: 0.6245\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.0882 - acc: 0.6174 - val_loss: 1.0008 - val_acc: 0.6488\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.0520 - acc: 0.6306 - val_loss: 1.0226 - val_acc: 0.6398\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.0208 - acc: 0.6400 - val_loss: 1.0428 - val_acc: 0.6370\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 1.0017 - acc: 0.6483 - val_loss: 0.9802 - val_acc: 0.6624\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.9777 - acc: 0.6575 - val_loss: 0.9837 - val_acc: 0.6611\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.9649 - acc: 0.6610 - val_loss: 1.0014 - val_acc: 0.6492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c836b7fd0>"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "    model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, verbose=1, mode='auto') \n",
    "    #Stop training when a monitored quantity has stopped improving.\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model\n",
    "    model4.fit(x_traincf, y_traincf, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_testcf, y_testcf), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN3vYYhK4W0u"
   },
   "source": [
    "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJbekTKi4cmM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_gen(image_rot=50 , width_shift_range=0.1,height_shift_range=0.1, horizontal_flip=True):\n",
    "    datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=image_rot,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=width_shift_range,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=horizontal_flip,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-SLtUhC4dK2"
   },
   "source": [
    "### **Prepare/fit the generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSw8Bv2_4hb0"
   },
   "outputs": [],
   "source": [
    "dgen=data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTmgKIu1giC0"
   },
   "outputs": [],
   "source": [
    "dgen.fit(x_traincf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "TdHh8GpxguFf",
    "outputId": "c2019ab1-1a3b-49bc-9beb-4047e8444017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   7/1562 [..............................] - ETA: 41s - loss: 2.0145 - acc: 0.3973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1562, epochs=10)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 38s 24ms/step - loss: 1.5803 - acc: 0.4446 - val_loss: 1.1613 - val_acc: 0.6090\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 38s 24ms/step - loss: 1.4989 - acc: 0.4683 - val_loss: 1.1408 - val_acc: 0.6059\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.4630 - acc: 0.4793 - val_loss: 1.1395 - val_acc: 0.6006\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.4355 - acc: 0.4909 - val_loss: 1.1103 - val_acc: 0.6194\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.4204 - acc: 0.4952 - val_loss: 1.0890 - val_acc: 0.6201\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.3956 - acc: 0.5058 - val_loss: 1.1884 - val_acc: 0.5949\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 38s 24ms/step - loss: 1.3796 - acc: 0.5069 - val_loss: 1.0741 - val_acc: 0.6241\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.3708 - acc: 0.5115 - val_loss: 1.0851 - val_acc: 0.6187\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.3549 - acc: 0.5187 - val_loss: 1.0902 - val_acc: 0.6253\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 37s 24ms/step - loss: 1.3469 - acc: 0.5204 - val_loss: 1.1084 - val_acc: 0.6149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c860bbe48>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit_generator(datagen.flow(x_traincf, y_traincf,\n",
    "                    batch_size=32),\n",
    "                    samples_per_epoch=x_traincf.shape[0],\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=(x_testcf, y_testcf), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYyF-P8O4jQ8"
   },
   "source": [
    "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "mXug4z234mwQ",
    "outputId": "313bd90b-7f66-467c-dab0-f33442f639de"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = dgen.flow(x_traincf[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
