{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFfDTfhlaEI_"
   },
   "source": [
    "# Transfer Learning MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "irckMwvUU6QT",
    "outputId": "79ed83f3-fafd-46df-da87-d01cba503572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qNoCpmsKz_EN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNwbqCFRaEJC"
   },
   "source": [
    "* Train a simple convnet on the MNIST dataset the first 5 digits [0-4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5-9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Dnzaw1i5sXF"
   },
   "source": [
    "## MNIST Dataset\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpUULy1Z5sXF"
   },
   "source": [
    "Let's import keras and load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiG7IPhm5sXG"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqUiJM_Z5sXL"
   },
   "outputs": [],
   "source": [
    "from keras.backend import backend\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVw4wsuW5sXO"
   },
   "source": [
    "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgQ86Vhw5sXP"
   },
   "source": [
    "Let's visualize some numbers using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "VZwg00gO5sXQ",
    "outputId": "f0d21ca9-f597-4d1e-ba5a-7515578aad6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93b48f9240>"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npdtZwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[1000]))\n",
    "plt.imshow(X_train[1000], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p64mhwp95sXS"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxNAiWYd5sXT"
   },
   "source": [
    "### Create two datasets\n",
    "- First having digits from 0 to 4\n",
    "- Second having digits from 5 to 9\n",
    "\n",
    "Hint: use labels to separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1807m1CL5sXT"
   },
   "outputs": [],
   "source": [
    "X_train1 , y_train1 = X_train[y_train <=4], y_train[y_train<=4] \n",
    "X_test1 , y_test1 = X_test[y_test <=4], y_test[y_test<=4]\n",
    "\n",
    "X_train2 , y_train2 = X_train[y_train >4], y_train[y_train>4] \n",
    "X_test2 , y_test2 = X_test[y_test >4], y_test[y_test>4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9jKcF1z5sXV"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMo7lvwQ5sXW"
   },
   "source": [
    "### Print shape of the data\n",
    "- print shape of all variables of both the datasets you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "kH7ZjEoH5sXW",
    "outputId": "0184fca1-b5f9-4498-c1cd-0886a215b2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30596, 28, 28)\n",
      "(30596,)\n",
      "(5139, 28, 28)\n",
      "(5139,)\n",
      "(29404, 28, 28)\n",
      "(29404,)\n",
      "(4861, 28, 28)\n",
      "(4861,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape)\n",
    "print(y_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(y_test1.shape)\n",
    "\n",
    "print(X_train2.shape)\n",
    "print(y_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUU4PkKU5sXY"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4I8ajqdt5sXY"
   },
   "source": [
    "### Reshape data\n",
    "- reshape first dataset\n",
    "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
    "- reshape features to pass it to a Conv2D layer\n",
    "- channel = 1\n",
    "- reshape features of first dataset only\n",
    "- do not reshape labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38wgBEcz5sXa"
   },
   "outputs": [],
   "source": [
    "X_train1 = X_train1.reshape(X_train1.shape[0], 28, 28,1).astype('float32')\n",
    "X_test1 = X_test1.reshape(X_test1.shape[0], 28, 28, 1).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5H-BtNm5sXg"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ahCMtCl5sXh"
   },
   "source": [
    "### Normalize data\n",
    "- normalize first dataset\n",
    "- we must normalize our data as it is always required in neural network models\n",
    "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
    "- normalize X_train and X_test\n",
    "- make sure that the values are float so that we can get decimal points after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4mti7pg5sXj"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "X_train1 /= 255\n",
    "X_test1 /= 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfQ6545D5sXp"
   },
   "source": [
    "### Print shape of data and number of images\n",
    "- for first dataset\n",
    "- print shape of X_train\n",
    "- print number of images in X_train\n",
    "- print number of images in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "uQfQXZMo5sXp",
    "outputId": "fecc24ff-ae28-4aa8-8738-8f53af8dcd0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train1.shape)\n",
    "print(X_train1.shape[0], 'train samples')\n",
    "print(X_test1.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oFjomSh5sXu"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lEFQQNk5sXu"
   },
   "source": [
    "### One-hot encode the class vector\n",
    "- encode labels of first dataset\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert y_train and y_test\n",
    "- number of classes: 5\n",
    "- we are doing this to use categorical_crossentropy as loss\n",
    "\n",
    "Hint: you can use keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aejx3Zb35sXv"
   },
   "outputs": [],
   "source": [
    "y_train1 = np_utils.to_categorical(y_train1, 5)\n",
    "y_test1 = np_utils.to_categorical(y_test1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlkiipRA5sXw"
   },
   "source": [
    "## Question 6\n",
    "We will build our model by using high level Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzYMC_xm5sXx"
   },
   "source": [
    "### Initialize a sequential model\n",
    "- define a sequential model\n",
    "- add 2 convolutional layers\n",
    "    - no of filters: 32\n",
    "    - kernel size: 3x3\n",
    "    - activation: \"relu\"\n",
    "    - input shape: (28, 28, 1) for first layer\n",
    "- add a max pooling layer of size 2x2\n",
    "- add a dropout layer\n",
    "    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n",
    "    - use dropout rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDr-HKl-5sXx"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "# Define the Type of Model\n",
    "model = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(28, 28,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "    \n",
    "    \n",
    "#Add a MaxPooling Layer of size 2X2 \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Apply Dropout with 0.2 probability \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2RaPWiP5sXz"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ajGIM6t5sXz"
   },
   "source": [
    "### Add classification layers\n",
    "- do this after doing question 6\n",
    "- flatten the data\n",
    "    - add Flatten later\n",
    "    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n",
    "- add 2 dense layers\n",
    "    - number of neurons in first layer: 128\n",
    "    - number of neurons in last layer: number of classes\n",
    "    - activation function in first layer: relu\n",
    "    - activation function in last layer: softmax\n",
    "    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes\n",
    "- you can add a dropout layer in between, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBxWAN265sX0"
   },
   "outputs": [],
   "source": [
    "num_classes=5\n",
    "\n",
    "#Flatten the layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
    "model.add(Dense(128, activation='relu',name='dense_1'))\n",
    "\n",
    "#Apply Dropout with 0.2 probability \n",
    "model.add(Dropout(0.2,name='drop_2'))\n",
    "\n",
    "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
    "model.add(Dense(num_classes, activation='softmax',name='dense_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lhtm4d5K5sX1"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmXg8EaF5sX2"
   },
   "source": [
    "### Compile and fit the model\n",
    "- compile your model\n",
    "    - loss: \"categorical_crossentropy\"\n",
    "    - metrics: \"accuracy\"\n",
    "    - optimizer: \"sgd\"\n",
    "- fit your model\n",
    "    - give train data - features and labels\n",
    "    - batch size: 128\n",
    "    - epochs: 10\n",
    "    - give validation data - features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgclxC8s5sX4"
   },
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3iBpK9BClw1b",
    "outputId": "c5066cba-a6a9-4768-ef42-ba9f9217de79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5139, 28, 28, 1)\n",
      "(5139, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test1.shape)\n",
    "print(y_test1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "ntWPiJ_7j5le",
    "outputId": "44e7df1e-c3dc-4ca9-af91-12ec0d207cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/10\n",
      "30596/30596 [==============================] - 4s 120us/step - loss: 0.5602 - acc: 0.8457 - val_loss: 0.1153 - val_acc: 0.9698\n",
      "Epoch 2/10\n",
      "30596/30596 [==============================] - 3s 98us/step - loss: 0.1611 - acc: 0.9506 - val_loss: 0.0879 - val_acc: 0.9745\n",
      "Epoch 3/10\n",
      "30596/30596 [==============================] - 3s 98us/step - loss: 0.1340 - acc: 0.9591 - val_loss: 0.0718 - val_acc: 0.9792\n",
      "Epoch 4/10\n",
      "30596/30596 [==============================] - 3s 99us/step - loss: 0.1163 - acc: 0.9640 - val_loss: 0.0888 - val_acc: 0.9700\n",
      "Epoch 5/10\n",
      "30596/30596 [==============================] - 3s 100us/step - loss: 0.1054 - acc: 0.9680 - val_loss: 0.1749 - val_acc: 0.9393\n",
      "Epoch 6/10\n",
      "30596/30596 [==============================] - 3s 99us/step - loss: 0.0995 - acc: 0.9693 - val_loss: 0.0503 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "30596/30596 [==============================] - 3s 101us/step - loss: 0.0867 - acc: 0.9736 - val_loss: 0.0453 - val_acc: 0.9868\n",
      "Epoch 8/10\n",
      "30596/30596 [==============================] - 3s 98us/step - loss: 0.0821 - acc: 0.9745 - val_loss: 0.0590 - val_acc: 0.9844\n",
      "Epoch 9/10\n",
      "30596/30596 [==============================] - 3s 98us/step - loss: 0.0789 - acc: 0.9753 - val_loss: 0.0390 - val_acc: 0.9887\n",
      "Epoch 10/10\n",
      "30596/30596 [==============================] - 3s 99us/step - loss: 0.0745 - acc: 0.9769 - val_loss: 0.0385 - val_acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93b48f9518>"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test1, y_test1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSVZUu3p5sX5"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5TQ3yLV5sX6"
   },
   "source": [
    "### Evaluate model\n",
    "- evaluate your model and get accuracy\n",
    "- use test features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "bBvuD3ba5sX7",
    "outputId": "ef0e325b-a9fe-4747-93e2-346d74c17e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5139/5139 [==============================] - 0s 90us/step\n",
      "Test loss: 0.03853719613795198\n",
      "Test accuracy: 0.9891029383148473\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test set\n",
    "score = model.evaluate(X_test1, y_test1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aUzOh9m5sX-"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srd-YYNH5sX-"
   },
   "source": [
    "## Transfer learning\n",
    "Now we will apply this model on second dataset (5-9 digits)\n",
    "\n",
    "- fix the first convolution layers so that the weights in the convolution layers dont get updated in the process of training\n",
    "- get the second dataset\n",
    "- train the last 2 dense layers\n",
    "- predict the accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvhdH7D55sYA"
   },
   "source": [
    "### Make only dense layers trainable\n",
    "- set trainalble = False for all layers other than Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "brN7VZHFaEJ4",
    "outputId": "ac187c30-f488-48f3-dc35-f69c66634bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mconv2d_11\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mactivation_11\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mconv2d_12\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mactivation_12\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mmax_pooling2d_5\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdropout_5\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mflatten_7\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_1\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mdrop_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_2\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Freezing layers in the model which don't have 'dense' in their name\n",
    "for layer in model.layers:\n",
    "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
    "    #Freezing a layer\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYR9VGzO5sYE"
   },
   "source": [
    "### Modify data\n",
    "- in your second data, class labels will start from 5 to 9 but for keras.utils.to_categorical the labels should start from 0\n",
    "- so you need to subtract 5 from train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lC5W75L35sYF"
   },
   "outputs": [],
   "source": [
    " y_train2 = y_train[y_train>4] - 5\n",
    " y_test2 =  y_test[y_test>4] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGY3OTBt5sYG"
   },
   "source": [
    "### Reshape data\n",
    "- reshape second dataset\n",
    "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
    "- reshape features to pass it to a Conv2D layer\n",
    "- channel = 1\n",
    "- reshape features of first dataset only\n",
    "- do not reshape labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0V7RUlRD5sYH"
   },
   "outputs": [],
   "source": [
    "X_train2 = X_train2.reshape(X_train2.shape[0], 28, 28,1).astype('float32')\n",
    "X_test2 = X_test2.reshape(X_test2.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7omqMQH5sYJ"
   },
   "source": [
    "### Normalize data\n",
    "- normalize second data\n",
    "- we must normalize our data as it is always required in neural network models\n",
    "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
    "- normalize X_train and X_test\n",
    "- make sure that the values are float so that we can get decimal points after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEFYNHRp5sYJ"
   },
   "outputs": [],
   "source": [
    "X_train2 /= 255\n",
    "X_test2 /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OfdlF655sYM"
   },
   "source": [
    "### Print shape of data and number of images\n",
    "- print shape of X_train\n",
    "- print number of images in X_train\n",
    "- print number of images in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "bZEkCQ-P5sYO",
    "outputId": "0aca2bd7-11c3-4c0d-c9e2-d5d31d575fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train2 shape:', X_train2.shape)\n",
    "print(X_train2.shape[0], 'train samples')\n",
    "print(X_test2.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_3-0Qwo5sYQ"
   },
   "source": [
    "### One-hot encode the class vector\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert y_train and y_test\n",
    "- number of classes: 5\n",
    "- we are doing this to use categorical_crossentropy as loss\n",
    "\n",
    "Hint: you can use keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k46Me5Re5sYR"
   },
   "outputs": [],
   "source": [
    "y_train2 = np_utils.to_categorical(y_train2, 5)\n",
    "y_test2 = np_utils.to_categorical(y_test2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "jMpwJWu-uqSG",
    "outputId": "b3a544c5-4d8c-48d3-d71e-e07296ecf385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29404, 28, 28, 1)\n",
      "(4861, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D9xEoW515sYS"
   },
   "source": [
    "### Fit the model\n",
    "- give train data - features and labels\n",
    "- batch size: 128\n",
    "- epochs: 10\n",
    "- give validation data - features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "B6f-XAc-5sYT",
    "outputId": "a06c65b0-54a1-4003-ac90-1a81566cb01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/10\n",
      "29404/29404 [==============================] - 3s 102us/step - loss: 0.4237 - acc: 0.8640 - val_loss: 0.1780 - val_acc: 0.9426\n",
      "Epoch 2/10\n",
      "29404/29404 [==============================] - 3s 98us/step - loss: 0.2091 - acc: 0.9326 - val_loss: 0.1289 - val_acc: 0.9593\n",
      "Epoch 3/10\n",
      "29404/29404 [==============================] - 3s 99us/step - loss: 0.1715 - acc: 0.9447 - val_loss: 0.1090 - val_acc: 0.9630\n",
      "Epoch 4/10\n",
      "29404/29404 [==============================] - 3s 97us/step - loss: 0.1519 - acc: 0.9504 - val_loss: 0.0960 - val_acc: 0.9696\n",
      "Epoch 5/10\n",
      "29404/29404 [==============================] - 3s 99us/step - loss: 0.1365 - acc: 0.9561 - val_loss: 0.0888 - val_acc: 0.9710\n",
      "Epoch 6/10\n",
      "29404/29404 [==============================] - 3s 98us/step - loss: 0.1252 - acc: 0.9581 - val_loss: 0.0837 - val_acc: 0.9712\n",
      "Epoch 7/10\n",
      "29404/29404 [==============================] - 3s 98us/step - loss: 0.1202 - acc: 0.9617 - val_loss: 0.0762 - val_acc: 0.9757\n",
      "Epoch 8/10\n",
      "29404/29404 [==============================] - 3s 99us/step - loss: 0.1125 - acc: 0.9649 - val_loss: 0.0765 - val_acc: 0.9739\n",
      "Epoch 9/10\n",
      "29404/29404 [==============================] - 3s 98us/step - loss: 0.1048 - acc: 0.9649 - val_loss: 0.0701 - val_acc: 0.9759\n",
      "Epoch 10/10\n",
      "29404/29404 [==============================] - 3s 97us/step - loss: 0.1000 - acc: 0.9666 - val_loss: 0.0667 - val_acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93b478d080>"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "85ginrII5sYV"
   },
   "source": [
    "### Evaluate model\n",
    "- evaluate your model and get accuracy\n",
    "- use test features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "k11-vrsm5sYW",
    "outputId": "62455bf0-5cb4-4c79-a40d-7e5eb764d40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4861/4861 [==============================] - 1s 103us/step\n",
      "Test loss: 0.06671723045563531\n",
      "Test accuracy: 0.9777823492004851\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test set\n",
    "score1 = model.evaluate(X_test2, y_test2)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTNhSDqn5sYY"
   },
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-HwvIdH0M-"
   },
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "The objective of the second problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
    "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIWWfNks5sYa"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAQDiZHRH0M_"
   },
   "source": [
    "### Read the data\n",
    "- read tweets.csv\n",
    "- use latin encoding if it gives encoding error while loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eXGIe-SH0NA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweetsdf = pd.read_csv(\"/content/drive/My Drive/Great Learning/tweets.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39pqw0aE5sYe"
   },
   "source": [
    "### Drop null values\n",
    "- drop all the rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BF_69oyI5sYf",
    "outputId": "e3131b95-b260-41b7-ac2f-90496dc624c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 167,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxvTZjOEyx7y"
   },
   "outputs": [],
   "source": [
    "new_tweetsdf = tweetsdf.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a1Dgjfmvy5u4",
    "outputId": "4d461013-9450-4f4b-9e87-73455c13ae6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3)"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweetsdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0bm4bDiy5sYg"
   },
   "source": [
    "### Print the dataframe\n",
    "- print initial 5 rows of the data\n",
    "- use df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "ceSlvAVa5sYh",
    "outputId": "451b57e0-4c60-422d-9c30-a23bca1a62f3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
       "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweetsdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcWfPVqG5sYi"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBbAeip_5sYj"
   },
   "source": [
    "### Preprocess data\n",
    "- convert all text to lowercase - use .lower()\n",
    "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
    "- strip all the text - use .strip()\n",
    "    - this is for removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PE4Bn_YT5sYj"
   },
   "outputs": [],
   "source": [
    "tweets= new_tweetsdf.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlMvbtrK5sYl"
   },
   "source": [
    "print dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "afocjaUn5sYm",
    "outputId": "58d33518-45c2-41d4-bf6e-76acd697560a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>ipad</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>google</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...  ...                                   negative emotion\n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  ...                                   positive emotion\n",
       "2  @swonderlin can not wait for #ipad 2 also. the...  ...                                   positive emotion\n",
       "3  @sxsw i hope this year's festival isn't as cra...  ...                                   negative emotion\n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...  ...                                   positive emotion\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihFJ1vmm3S_U"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s+#_]' if not remove_digits else r'[^a-zA-z0-9\\s+#_]'\n",
    "    text = re.sub(pattern, '', str(text))\n",
    "    lentext = len(text)\n",
    "    print(lentext)\n",
    "    afterstrip= text.strip()\n",
    "    print(len(afterstrip))\n",
    "    return afterstrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TRZsrBKE4YfV",
    "outputId": "d475527e-9676-4bab-9302-ecc22bce36f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6479\n",
      "6434\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "tweetsnew=remove_special_characters(tweets, remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "JKdPrKjhEgSR",
    "outputId": "b23d7a4e-cb06-4acd-c8fd-50053594da2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweet_text   is_there_an_emotion_directed_at_a_brand_or_product\\n0     wesley83 i have a 3g iphone after 3 hrs twe                                     negative emotion\\n1     jessedee know about fludapp  awesome ipadi                                     positive emotion\\n2     swonderlin can not wait for #ipad 2 also the                                     positive emotion\\n3     sxsw i hope this years festival isnt as cra                                     negative emotion\\n4     sxtxstate great stuff on fri #sxsw marissa m                                     positive emotion\\n7     #sxsw is just starting #ctia is around the co                                     positive emotion\\n8     beautifully smart and simple idea rt madebyma                                     positive emotion\\n9     counting down the days to #sxsw plus strong ca                                     positive emotion\\n10    excited to meet the samsungmobileus at #sxsw                                      positive emotion\\n11    find amp start impromptu parties at #sxsw wi                                     positive emotion\\n12    foursquare ups the game just in time for #sxs                                     positive emotion\\n13    gotta love this #sxsw google calendar featurin                                     positive emotion\\n14    great #sxsw ipad app from madebymany http                                     positive emotion\\n15    haha awesomely rad ipad app by madebymany ht                                     positive emotion\\n17    i just noticed dst is coming this weekend how                                     negative emotion\\n18    just added my #sxsw flights to planely match                                     positive emotion\\n19    must have #sxsw app rt malbonster lovely re                                     positive emotion\\n20    need to buy an ipad2 while im in austin at #s                                     positive emotion\\n21    oh my god the #sxsw app for ipad is pure u                                     positive emotion\\n22    okay this is really it yay new foursquare f                                     positive emotion\\n23    photo just installed the #sxsw iphone app wh                                     positive emotion\\n24    really enjoying the changes in gowalla 30 for                                     positive emotion\\n25    rt laurieshook im looking forward to the #s                                     positive emotion\\n26    rt haha awesomely rad ipad app by madebymany                                     positive emotion\\n27    someone started an #austin partnerhub group i                                     positive emotion\\n28    the new #4sq3 looks like it is going to rock                                      positive emotion\\n29    they were right the gowalla 3 app on #androi                                     positive emotion\\n30    very smart from madebymany #hollergram ipad a                                     positive emotion\\n31    you must have this app for your ipad if you ar                                     positive emotion\\n36    the best  rt mention ha first in line for #                                     positive emotion\\n                                                                                                   \\n9008  im pretty sure the panelist that thinks quot                                     negative emotion\\n9009  very happy that discovr has been named as one                                      positive emotion\\n9012  apparently there is an ipad and iphone app to                                      positive emotion\\n9013  on the way to #sxsw see you all tonight hope                                     positive emotion\\n9017  stopped by tron legacy lounge at  #sxsw audio                                     positive emotion\\n9018  second day using my apple ipad2 at #sxsw and i                                     positive emotion\\n9022  by the way i love that yall are so down to d                                     positive emotion\\n9025  absolutely  rt mention timely good schtuff f                                     positive emotion\\n9027  good job yall  rt mention yes gowalla wins                                     positive emotion\\n9029  [top story] at #sxsw apple schools the market                                     positive emotion\\n9033  mention yep i cant believe they set up a po                                     positive emotion\\n9035  mention yes i picked up the ipad 2 at #sxsw                                     positive emotion\\n9036  mention yes thats why i favorited it i wan                                     positive emotion\\n9044  look everyone zomg mention got an ipad 2 on                                      positive emotion\\n9045  mention you are my favorite thanks for comi                                     positive emotion\\n9048  mention you bet man kindle and apple for sur                                     positive emotion\\n9051  mention you can get an ipad 1 for under 350                    no emotion toward brand or product\\n9060  mention you might also appreciate new iphone                                      positive emotion\\n9061  mention you realize im still padless i just                                     positive emotion\\n9063  mention you should get the ipad 2  to save yo                                     positive emotion\\n9064  mention you should see the line here at #sxsw                                     positive emotion\\n9066  how much you want to bet apple is disproportio                                         i cant tell\\n9070  you know youve made it to #sxsw when you see                                      positive emotion\\n9071  what are your essentials for #sxsw  mine poc                                     positive emotion\\n9072  mention your iphone 4 cases are rad and ready                                     positive emotion\\n9077  mention your pr guy just convinced me to swit                                     positive emotion\\n9079  quotpapyrussort of like the ipadquot                                       positive emotion\\n9080  diller says google tv quotmight be run over                                      negative emotion\\n9085  ive always used camera+ for my iphone bc it                                      positive emotion\\n9088                      ipad everywhere #sxsw link                                     positive emotion\\n\\n[3291 rows x 3 columns]'"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcTUnvtg5sYn"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gnaeSXZ5sYo"
   },
   "source": [
    "### Preprocess data\n",
    "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
    "- find the value counts of \"positive emotion\" and \"negative emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RknwueqN__Mf",
    "outputId": "16f0ddff-2172-4013-8ea0-b53584935fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Negative emotion\n",
       "1                         Positive emotion\n",
       "2                         Positive emotion\n",
       "3                         Negative emotion\n",
       "4                         Positive emotion\n",
       "7                         Positive emotion\n",
       "8                         Positive emotion\n",
       "9                         Positive emotion\n",
       "10                        Positive emotion\n",
       "11                        Positive emotion\n",
       "12                        Positive emotion\n",
       "13                        Positive emotion\n",
       "14                        Positive emotion\n",
       "15                        Positive emotion\n",
       "17                        Negative emotion\n",
       "18                        Positive emotion\n",
       "19                        Positive emotion\n",
       "20                        Positive emotion\n",
       "21                        Positive emotion\n",
       "22                        Positive emotion\n",
       "23                        Positive emotion\n",
       "24                        Positive emotion\n",
       "25                        Positive emotion\n",
       "26                        Positive emotion\n",
       "27                        Positive emotion\n",
       "28                        Positive emotion\n",
       "29                        Positive emotion\n",
       "30                        Positive emotion\n",
       "31                        Positive emotion\n",
       "36                        Positive emotion\n",
       "                       ...                \n",
       "9008                      Negative emotion\n",
       "9009                      Positive emotion\n",
       "9012                      Positive emotion\n",
       "9013                      Positive emotion\n",
       "9017                      Positive emotion\n",
       "9018                      Positive emotion\n",
       "9022                      Positive emotion\n",
       "9025                      Positive emotion\n",
       "9027                      Positive emotion\n",
       "9029                      Positive emotion\n",
       "9033                      Positive emotion\n",
       "9035                      Positive emotion\n",
       "9036                      Positive emotion\n",
       "9044                      Positive emotion\n",
       "9045                      Positive emotion\n",
       "9048                      Positive emotion\n",
       "9051    No emotion toward brand or product\n",
       "9060                      Positive emotion\n",
       "9061                      Positive emotion\n",
       "9063                      Positive emotion\n",
       "9064                      Positive emotion\n",
       "9066                          I can't tell\n",
       "9070                      Positive emotion\n",
       "9071                      Positive emotion\n",
       "9072                      Positive emotion\n",
       "9077                      Positive emotion\n",
       "9079                      Positive emotion\n",
       "9080                      Negative emotion\n",
       "9085                      Positive emotion\n",
       "9088                      Positive emotion\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, Length: 3291, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweetsdf.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "llGbw-G8AT4q",
    "outputId": "b9a8af56-48d8-4917-b371-77cff3537d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweetsdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nLewJh_35sYp",
    "outputId": "1aa6f34f-dc68-44e2-e881-06385eff742d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW Wi...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXS...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gotta love this #SXSW Google Calendar featurin...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Great #sxsw ipad app from @madebymany: http://...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>haha, awesomely rad iPad app by @madebymany ht...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just added my #SXSW flights to @planely. Match...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Must have #SXSW app! RT @malbonster: Lovely re...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #s...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh. My. God. The #SXSW app for iPad is pure, u...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Okay, this is really it: yay new @Foursquare f...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo: Just installed the #SXSW iPhone app, wh...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @LaurieShook: I'm looking forward to the #S...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT haha, awesomely rad iPad app by @madebymany...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>someone started an #austin @PartnerHub group i...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The new #4sq3 looks like it is going to rock. ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>They were right, the @gowalla 3 app on #androi...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Very smart from @madebymany #hollergram iPad a...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You must have this app for your iPad if you ar...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The best!  RT @mention Ha! First in line for #...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>@mention  - Great weather to greet you for #sx...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#IPad2 's #SmartCover Opens to Instant A...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>HOORAY RT @mention Apple Is Opening A Pop-U...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>Getting my ipad2 #sxsw (@mention Apple Store w...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>Data on my iPhone finally sorted. Next stop: #...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>Dropped my MacBook pro as I was walking into #...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9006</th>\n",
       "      <td>Creativity prompt: use Google maps to virtuall...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>Very happy that Discovr has been named as one ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>Apparently there is an iPad and iPhone app to ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>On the way to #sxsw, see you all tonight! hope...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>Stopped by Tron Legacy Lounge at  #SXSW. Audio...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>Second day using my Apple iPad2 at #SXSW and I...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>By the way, I love that y'all are so down to d...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9025</th>\n",
       "      <td>Absolutely!  RT @mention Timely good schtuff f...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>Good job y'all!  RT @mention Yes! Gowalla wins...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9029</th>\n",
       "      <td>[TOP STORY] At #SXSW, Apple schools the market...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>@mention yep! I can't believe they set up a po...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9035</th>\n",
       "      <td>@mention Yes, I picked up the ipad 2 at #SXSW....</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9036</th>\n",
       "      <td>@mention Yes, that's why I favorited it! I wan...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>Look everyone! Zomg @mention got an iPad 2 on ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>@mention you are my favorite-- thanks for comi...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9048</th>\n",
       "      <td>@mention You bet man! Kindle and Apple for sur...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>@mention you might also appreciate new iPhone ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>@mention You realize I'm still padless? I just...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9063</th>\n",
       "      <td>@mention You should get the iPad 2  to save yo...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>@mention you should see the line here at #SXSW...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>You know you've made it to #sxsw when you see ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>what are your essentials for #SxSW?  Mine? poc...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>@mention your iPhone 4 cases are Rad and Ready...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>@mention your PR guy just convinced me to swit...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2672 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
       "7     #SXSW is just starting, #CTIA is around the co...  ...                                   Positive emotion\n",
       "8     Beautifully smart and simple idea RT @madebyma...  ...                                   Positive emotion\n",
       "9     Counting down the days to #sxsw plus strong Ca...  ...                                   Positive emotion\n",
       "10    Excited to meet the @samsungmobileus at #sxsw ...  ...                                   Positive emotion\n",
       "11    Find &amp; Start Impromptu Parties at #SXSW Wi...  ...                                   Positive emotion\n",
       "12    Foursquare ups the game, just in time for #SXS...  ...                                   Positive emotion\n",
       "13    Gotta love this #SXSW Google Calendar featurin...  ...                                   Positive emotion\n",
       "14    Great #sxsw ipad app from @madebymany: http://...  ...                                   Positive emotion\n",
       "15    haha, awesomely rad iPad app by @madebymany ht...  ...                                   Positive emotion\n",
       "18    Just added my #SXSW flights to @planely. Match...  ...                                   Positive emotion\n",
       "19    Must have #SXSW app! RT @malbonster: Lovely re...  ...                                   Positive emotion\n",
       "20    Need to buy an iPad2 while I'm in Austin at #s...  ...                                   Positive emotion\n",
       "21    Oh. My. God. The #SXSW app for iPad is pure, u...  ...                                   Positive emotion\n",
       "22    Okay, this is really it: yay new @Foursquare f...  ...                                   Positive emotion\n",
       "23    Photo: Just installed the #SXSW iPhone app, wh...  ...                                   Positive emotion\n",
       "24    Really enjoying the changes in Gowalla 3.0 for...  ...                                   Positive emotion\n",
       "25    RT @LaurieShook: I'm looking forward to the #S...  ...                                   Positive emotion\n",
       "26    RT haha, awesomely rad iPad app by @madebymany...  ...                                   Positive emotion\n",
       "27    someone started an #austin @PartnerHub group i...  ...                                   Positive emotion\n",
       "28    The new #4sq3 looks like it is going to rock. ...  ...                                   Positive emotion\n",
       "29    They were right, the @gowalla 3 app on #androi...  ...                                   Positive emotion\n",
       "30    Very smart from @madebymany #hollergram iPad a...  ...                                   Positive emotion\n",
       "31    You must have this app for your iPad if you ar...  ...                                   Positive emotion\n",
       "36    The best!  RT @mention Ha! First in line for #...  ...                                   Positive emotion\n",
       "40    @mention  - Great weather to greet you for #sx...  ...                                   Positive emotion\n",
       "45    #IPad2 's #SmartCover Opens to Instant A...  ...                                   Positive emotion\n",
       "47    HOORAY RT @mention Apple Is Opening A Pop-U...  ...                                   Positive emotion\n",
       "...                                                 ...  ...                                                ...\n",
       "8996  Getting my ipad2 #sxsw (@mention Apple Store w...  ...                                   Positive emotion\n",
       "8997  Data on my iPhone finally sorted. Next stop: #...  ...                                   Positive emotion\n",
       "9000  Dropped my MacBook pro as I was walking into #...  ...                                   Positive emotion\n",
       "9006  Creativity prompt: use Google maps to virtuall...  ...                                   Positive emotion\n",
       "9009  Very happy that Discovr has been named as one ...  ...                                   Positive emotion\n",
       "9012  Apparently there is an iPad and iPhone app to ...  ...                                   Positive emotion\n",
       "9013  On the way to #sxsw, see you all tonight! hope...  ...                                   Positive emotion\n",
       "9017  Stopped by Tron Legacy Lounge at  #SXSW. Audio...  ...                                   Positive emotion\n",
       "9018  Second day using my Apple iPad2 at #SXSW and I...  ...                                   Positive emotion\n",
       "9022  By the way, I love that y'all are so down to d...  ...                                   Positive emotion\n",
       "9025  Absolutely!  RT @mention Timely good schtuff f...  ...                                   Positive emotion\n",
       "9027  Good job y'all!  RT @mention Yes! Gowalla wins...  ...                                   Positive emotion\n",
       "9029  [TOP STORY] At #SXSW, Apple schools the market...  ...                                   Positive emotion\n",
       "9033  @mention yep! I can't believe they set up a po...  ...                                   Positive emotion\n",
       "9035  @mention Yes, I picked up the ipad 2 at #SXSW....  ...                                   Positive emotion\n",
       "9036  @mention Yes, that's why I favorited it! I wan...  ...                                   Positive emotion\n",
       "9044  Look everyone! Zomg @mention got an iPad 2 on ...  ...                                   Positive emotion\n",
       "9045  @mention you are my favorite-- thanks for comi...  ...                                   Positive emotion\n",
       "9048  @mention You bet man! Kindle and Apple for sur...  ...                                   Positive emotion\n",
       "9060  @mention you might also appreciate new iPhone ...  ...                                   Positive emotion\n",
       "9061  @mention You realize I'm still padless? I just...  ...                                   Positive emotion\n",
       "9063  @mention You should get the iPad 2  to save yo...  ...                                   Positive emotion\n",
       "9064  @mention you should see the line here at #SXSW...  ...                                   Positive emotion\n",
       "9070  You know you've made it to #sxsw when you see ...  ...                                   Positive emotion\n",
       "9071  what are your essentials for #SxSW?  Mine? poc...  ...                                   Positive emotion\n",
       "9072  @mention your iPhone 4 cases are Rad and Ready...  ...                                   Positive emotion\n",
       "9077  @mention your PR guy just convinced me to swit...  ...                                   Positive emotion\n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...  ...                                   Positive emotion\n",
       "9085  I've always used Camera+ for my iPhone b/c it ...  ...                                   Positive emotion\n",
       "9088                      Ipad everywhere. #SXSW {link}  ...                                   Positive emotion\n",
       "\n",
       "[2672 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twtDF=twtDF[(twtDF['is_there_an_emotion_directed_at_a_brand_or_product']=='positive emotion') | (twtDF['is_there_an_emotion_directed_at_a_brand_or_product']=='negative emotion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "sNotihP7AbXe",
    "outputId": "8ac24161-521c-4b61-ef96-79f09a5c92a0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-56179bc6b15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltereddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filtereddf' is not defined"
     ]
    }
   ],
   "source": [
    "filtereddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VFYB4eh5sYr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6icGcVTE5sYz"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg0rSepj5sYz"
   },
   "source": [
    "### Encode labels\n",
    "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "    - change \"positive emotion\" to 1\n",
    "    - change \"negative emotion\" to 0\n",
    "- use map function to replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YftKwFv7H0N9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sC1qSe3h5sY2"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWlAN_Ts5sY2"
   },
   "source": [
    "### Get feature and label\n",
    "- get column \"tweet_text\" as feature\n",
    "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A3sOZzR5sY4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### Create train and test data\n",
    "- use train_test_split to get train and test set\n",
    "- set a random_state\n",
    "- test_size: 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNkwrGgEH0OA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMok2IX35sY8"
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSqYjPuT5sY8"
   },
   "source": [
    "### Vectorize data\n",
    "- create document-term matrix\n",
    "- use CountVectorizer()\n",
    "    - ngram_range: (1, 2)\n",
    "    - stop_words: 'english'\n",
    "    - min_df: 2   \n",
    "- do fit_transform on X_train\n",
    "- do transform on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bb9PnnqT5sY8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qanDXve15sY_"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMaRNFkV5sY_"
   },
   "source": [
    "### Select classifier logistic regression\n",
    "- use logistic regression for predicting sentiment of the given tweet\n",
    "- initialize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT3dNgB55sZA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqQ6_HX35sZD"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIzvnNkq5sZD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZpMsYQF5sZF"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGnQnUww5sZF"
   },
   "source": [
    "### Select classifier naive bayes\n",
    "- use naive bayes for predicting sentiment of the given tweet\n",
    "- initialize classifier\n",
    "- use MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AbVYssaH0OE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEaG942m5sZI"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLwRBj1R5sZI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7mgwYDJ5sZM"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZkA3tce5sZN"
   },
   "source": [
    "### Make predictions on logistic regression\n",
    "- use your trained logistic regression model to make predictions on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3f0M1ch5sZO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrIxjMUB5sZQ"
   },
   "source": [
    "### Make predictions on naive bayes\n",
    "- use your trained naive bayes model to make predictions on X_test\n",
    "- use a different variable name to store predictions so that they are kept separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSQnwyLU5sZQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwXQUE7b5sZS"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6SITIE75sZT"
   },
   "source": [
    "### Calculate accuracy of logistic regression\n",
    "- check accuracy of logistic regression classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clv2X0kKH0Ok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fd_Gnd05sZV"
   },
   "source": [
    "### Calculate accuracy of naive bayes\n",
    "- check accuracy of naive bayes classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d32uBpHi5sZW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_Internal_Lab_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
